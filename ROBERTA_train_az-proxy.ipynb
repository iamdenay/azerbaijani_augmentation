{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#How-to-train-a-new-language-model-from-scratch-using-Transformers-and-Tokenizers\" data-toc-modified-id=\"How-to-train-a-new-language-model-from-scratch-using-Transformers-and-Tokenizers-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>How to train a new language model from scratch using Transformers and Tokenizers</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Notebook-edition-(link-to-blogpost-link).-Last-update-May-15,-2020\" data-toc-modified-id=\"Notebook-edition-(link-to-blogpost-link).-Last-update-May-15,-2020-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Notebook edition (link to blogpost <a href=\"https://huggingface.co/blog/how-to-train\" target=\"_blank\">link</a>). Last update May 15, 2020</a></span></li></ul></li><li><span><a href=\"#1.-Find-a-dataset\" data-toc-modified-id=\"1.-Find-a-dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>1. Find a dataset</a></span></li><li><span><a href=\"#2.-Train-a-tokenizer\" data-toc-modified-id=\"2.-Train-a-tokenizer-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>2. Train a tokenizer</a></span></li><li><span><a href=\"#3.-Train-a-language-model-from-scratch\" data-toc-modified-id=\"3.-Train-a-language-model-from-scratch-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>3. Train a language model from scratch</a></span><ul class=\"toc-item\"><li><span><a href=\"#We'll-define-the-following-config-for-the-model\" data-toc-modified-id=\"We'll-define-the-following-config-for-the-model-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>We'll define the following config for the model</a></span></li><li><span><a href=\"#Now-let's-build-our-training-Dataset\" data-toc-modified-id=\"Now-let's-build-our-training-Dataset-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Now let's build our training Dataset</a></span></li><li><span><a href=\"#Finally,-we-are-all-set-to-initialize-our-Trainer\" data-toc-modified-id=\"Finally,-we-are-all-set-to-initialize-our-Trainer-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Finally, we are all set to initialize our Trainer</a></span></li><li><span><a href=\"#Start-training\" data-toc-modified-id=\"Start-training-1.3.4\"><span class=\"toc-item-num\">1.3.4&nbsp;&nbsp;</span>Start training</a></span><ul class=\"toc-item\"><li><span><a href=\"#üéâ-Save-final-model-(+-tokenizer-+-config)-to-disk\" data-toc-modified-id=\"üéâ-Save-final-model-(+-tokenizer-+-config)-to-disk-1.3.4.1\"><span class=\"toc-item-num\">1.3.4.1&nbsp;&nbsp;</span>üéâ Save final model (+ tokenizer + config) to disk</a></span></li></ul></li></ul></li><li><span><a href=\"#4.-Check-that-the-LM-actually-trained\" data-toc-modified-id=\"4.-Check-that-the-LM-actually-trained-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>4. Check that the LM actually trained</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1oqh0F6W3ad"
   },
   "source": [
    "# How to train a new language model from scratch using Transformers and Tokenizers\n",
    "\n",
    "### Notebook edition (link to blogpost [link](https://huggingface.co/blog/how-to-train)). Last update May 15, 2020\n",
    "\n",
    "\n",
    "Over the past few months, we made several improvements to our [`transformers`](https://github.com/huggingface/transformers) and [`tokenizers`](https://github.com/huggingface/tokenizers) libraries, with the goal of making it easier than ever to **train a new language model from scratch**.\n",
    "\n",
    "In this post we‚Äôll demo how to train a ‚Äúsmall‚Äù model (84 M parameters = 6 layers, 768 hidden size, 12 attention heads) ‚Äì that‚Äôs the same number of layers & heads as DistilBERT ‚Äì on **Esperanto**. We‚Äôll then fine-tune the model on a downstream task of part-of-speech tagging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find a dataset\n",
    "\n",
    "First, let us find a corpus of text in Esperanto. Here we‚Äôll use the Esperanto portion of the [OSCAR corpus](https://traces1.inria.fr/oscar/) from INRIA.\n",
    "OSCAR is a huge multilingual corpus obtained by language classification and filtering of [Common Crawl](https://commoncrawl.org/) dumps of the Web.\n",
    "\n",
    "<img src=\"https://huggingface.co/blog/assets/01_how-to-train/oscar.png\" style=\"margin: auto; display: block; width: 260px;\">\n",
    "\n",
    "The Esperanto portion of the dataset is only 299M, so we‚Äôll concatenate with the Esperanto sub-corpus of the [Leipzig Corpora Collection](https://wortschatz.uni-leipzig.de/en/download), which is comprised of text from diverse sources like news, literature, and wikipedia.\n",
    "\n",
    "The final training corpus has a size of 3 GB, which is still small ‚Äì for your model, you will get better results the more data you can get to pretrain on. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-kkz81OY6xH"
   },
   "source": [
    "## 2. Train a tokenizer\n",
    "\n",
    "We choose to train a byte-level Byte-pair encoding tokenizer (the same as GPT-2), with the same special tokens as RoBERTa. Let‚Äôs arbitrarily pick its size to be 52,000.\n",
    "\n",
    "We recommend training a byte-level BPE (rather than let‚Äôs say, a WordPiece tokenizer like BERT) because it will start building its vocabulary from an alphabet of single bytes, so all words will be decomposable into tokens (no more `<unk>` tokens!).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T08:51:06.722937Z",
     "start_time": "2021-05-05T08:49:59.903365Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy these two values from the JSON file so generated\n",
      "Downloading kazakhoscarcorpus.zip to /home/ubuntu/ATABA/src/kazBert\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 636M/636M [01:01<00:00, 11.3MB/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 636M/636M [01:01<00:00, 10.8MB/s]\n",
      "unzip:  cannot find or open /content/examine-the-examiner.zip, /content/examine-the-examiner.zip.zip or /content/examine-the-examiner.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "#For a kaggle username & key, just go to your kaggle account and generate key\n",
    "#The JSON file so downloaded contains both of them\n",
    "if(\"examine-the-examiner.zip\" not in os.listdir()):\n",
    "  print(\"Copy these two values from the JSON file so generated\")\n",
    "  os.environ['KAGGLE_USERNAME'] = \"iamdenay\"\n",
    "  os.environ['KAGGLE_KEY'] =  \"3601827abd9232de7a43a10964bde3c0\"\n",
    "  !kaggle datasets download -d zhaseke/kazakhoscarcorpus\n",
    "  !unzip /content/examine-the-examiner.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T08:57:20.887952Z",
     "start_time": "2021-05-05T08:57:20.838668Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._resume_backend at 0x7f3c80679a60> (for pre_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_resume_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resuming backend\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_jupyter_teardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_resume\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[0mresume\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResumeRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunRecord\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _WandbInit._pause_backend at 0x7f3c80679510> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "The wandb backend process has shutdown",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/backcall/backcall.py\u001b[0m in \u001b[0;36madapted\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m#            print(args, kwargs, unmatched_pos, cut_positional, unmatched_kw)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36m_pause_backend\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"saved code: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpublish_pause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_resume_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36mpublish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0mpause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPauseRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpublish_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/wandb/sdk/interface/interface.py\u001b[0m in \u001b[0;36m_publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_publish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRecord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The wandb backend process has shutdown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: The wandb backend process has shutdown"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T08:58:51.961281Z",
     "start_time": "2021-05-05T08:57:22.807810Z"
    },
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": true
    },
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki_84\n",
      "wiki_92\n",
      "wiki_25\n",
      "wiki_17\n",
      "wiki_51\n",
      "wiki_97\n",
      "wiki_18\n",
      "wiki_45\n",
      "wiki_26\n",
      "wiki_21\n",
      "wiki_34\n",
      "wiki_80\n",
      "wiki_59\n",
      "wiki_62\n",
      "wiki_70\n",
      "wiki_69\n",
      "wiki_49\n",
      "wiki_91\n",
      "wiki_60\n",
      "wiki_03\n",
      "wiki_02\n",
      "wiki_66\n",
      "wiki_46\n",
      "wiki_28\n",
      "wiki_40\n",
      "wiki_65\n",
      "wiki_73\n",
      "wiki_85\n",
      "wiki_36\n",
      "wiki_23\n",
      "wiki_42\n",
      "wiki_68\n",
      "wiki_54\n",
      "wiki_52\n",
      "wiki_83\n",
      "wiki_08\n",
      "wiki_11\n",
      "wiki_82\n",
      "wiki_95\n",
      "wiki_44\n",
      "wiki_61\n",
      "wiki_48\n",
      "wiki_43\n",
      "wiki_31\n",
      "wiki_19\n",
      "wiki_78\n",
      "wiki_29\n",
      "wiki_37\n",
      "wiki_74\n",
      "wiki_79\n",
      "wiki_39\n",
      "wiki_13\n",
      "wiki_98\n",
      "wiki_47\n",
      "wiki_12\n",
      "wiki_32\n",
      "wiki_71\n",
      "wiki_63\n",
      "wiki_20\n",
      "wiki_81\n",
      "wiki_86\n",
      "wiki_76\n",
      "wiki_58\n",
      "wiki_88\n",
      "wiki_27\n",
      "wiki_94\n",
      "wiki_96\n",
      "wiki_56\n",
      "wiki_05\n",
      "wiki_53\n",
      "wiki_64\n",
      "wiki_35\n",
      "wiki_41\n",
      "wiki_55\n",
      "wiki_38\n",
      "wiki_89\n",
      "wiki_04\n",
      "wiki_30\n",
      "wiki_33\n",
      "wiki_75\n",
      "wiki_07\n",
      "wiki_22\n",
      "wiki_00\n",
      "wiki_77\n",
      "wiki_15\n",
      "wiki_16\n",
      "wiki_93\n",
      "wiki_50\n",
      "wiki_72\n",
      "wiki_24\n",
      "wiki_01\n",
      "wiki_87\n",
      "wiki_57\n",
      "wiki_06\n",
      "wiki_90\n",
      "wiki_09\n",
      "wiki_10\n",
      "wiki_99\n",
      "wiki_14\n",
      "wiki_67\n",
      "wiki_84\n",
      "wiki_92\n",
      "wiki_25\n",
      "wiki_17\n",
      "wiki_51\n",
      "wiki_97\n",
      "wiki_18\n",
      "wiki_45\n",
      "wiki_26\n",
      "wiki_21\n",
      "wiki_34\n",
      "wiki_80\n",
      "wiki_59\n",
      "wiki_62\n",
      "wiki_70\n",
      "wiki_69\n",
      "wiki_49\n",
      "wiki_91\n",
      "wiki_60\n",
      "wiki_03\n",
      "wiki_02\n",
      "wiki_66\n",
      "wiki_46\n",
      "wiki_28\n",
      "wiki_40\n",
      "wiki_65\n",
      "wiki_73\n",
      "wiki_85\n",
      "wiki_36\n",
      "wiki_23\n",
      "wiki_42\n",
      "wiki_68\n",
      "wiki_54\n",
      "wiki_52\n",
      "wiki_83\n",
      "wiki_08\n",
      "wiki_11\n",
      "wiki_82\n",
      "wiki_95\n",
      "wiki_44\n",
      "wiki_61\n",
      "wiki_48\n",
      "wiki_43\n",
      "wiki_31\n",
      "wiki_19\n",
      "wiki_78\n",
      "wiki_29\n",
      "wiki_37\n",
      "wiki_74\n",
      "wiki_79\n",
      "wiki_39\n",
      "wiki_13\n",
      "wiki_98\n",
      "wiki_47\n",
      "wiki_12\n",
      "wiki_32\n",
      "wiki_71\n",
      "wiki_63\n",
      "wiki_20\n",
      "wiki_81\n",
      "wiki_86\n",
      "wiki_76\n",
      "wiki_58\n",
      "wiki_88\n",
      "wiki_27\n",
      "wiki_94\n",
      "wiki_96\n",
      "wiki_56\n",
      "wiki_05\n",
      "wiki_53\n",
      "wiki_64\n",
      "wiki_35\n",
      "wiki_41\n",
      "wiki_55\n",
      "wiki_38\n",
      "wiki_89\n",
      "wiki_04\n",
      "wiki_30\n",
      "wiki_33\n",
      "wiki_75\n",
      "wiki_07\n",
      "wiki_22\n",
      "wiki_00\n",
      "wiki_77\n",
      "wiki_15\n",
      "wiki_16\n",
      "wiki_93\n",
      "wiki_50\n",
      "wiki_72\n",
      "wiki_24\n",
      "wiki_01\n",
      "wiki_87\n",
      "wiki_57\n",
      "wiki_06\n",
      "wiki_90\n",
      "wiki_09\n",
      "wiki_10\n",
      "wiki_99\n",
      "wiki_14\n",
      "wiki_67\n",
      "kk.txt\n",
      "wiki_84\n",
      "wiki_92\n",
      "wiki_25\n",
      "wiki_17\n",
      "wiki_51\n",
      "wiki_97\n",
      "wiki_18\n",
      "wiki_45\n",
      "wiki_26\n",
      "wiki_21\n",
      "wiki_34\n",
      "wiki_80\n",
      "wiki_59\n",
      "wiki_62\n",
      "wiki_70\n",
      "wiki_69\n",
      "wiki_49\n",
      "wiki_91\n",
      "wiki_60\n",
      "wiki_03\n",
      "wiki_02\n",
      "wiki_66\n",
      "wiki_46\n",
      "wiki_28\n",
      "wiki_40\n",
      "wiki_65\n",
      "wiki_73\n",
      "wiki_85\n",
      "wiki_36\n",
      "wiki_23\n",
      "wiki_42\n",
      "wiki_68\n",
      "wiki_54\n",
      "wiki_52\n",
      "wiki_83\n",
      "wiki_08\n",
      "wiki_11\n",
      "wiki_82\n",
      "wiki_95\n",
      "wiki_44\n",
      "wiki_61\n",
      "wiki_48\n",
      "wiki_43\n",
      "wiki_31\n",
      "wiki_19\n",
      "wiki_78\n",
      "wiki_29\n",
      "wiki_37\n",
      "wiki_74\n",
      "wiki_79\n",
      "wiki_39\n",
      "wiki_13\n",
      "wiki_98\n",
      "wiki_47\n",
      "wiki_12\n",
      "wiki_32\n",
      "wiki_71\n",
      "wiki_63\n",
      "wiki_20\n",
      "wiki_81\n",
      "wiki_86\n",
      "wiki_76\n",
      "wiki_58\n",
      "wiki_88\n",
      "wiki_27\n",
      "wiki_94\n",
      "wiki_96\n",
      "wiki_56\n",
      "wiki_05\n",
      "wiki_53\n",
      "wiki_64\n",
      "wiki_35\n",
      "wiki_41\n",
      "wiki_55\n",
      "wiki_38\n",
      "wiki_89\n",
      "wiki_04\n",
      "wiki_30\n",
      "wiki_33\n",
      "wiki_75\n",
      "wiki_07\n",
      "wiki_22\n",
      "wiki_00\n",
      "wiki_77\n",
      "wiki_15\n",
      "wiki_16\n",
      "wiki_93\n",
      "wiki_50\n",
      "wiki_72\n",
      "wiki_24\n",
      "wiki_01\n",
      "wiki_87\n",
      "wiki_57\n",
      "wiki_06\n",
      "wiki_90\n",
      "wiki_09\n",
      "wiki_10\n",
      "wiki_99\n",
      "wiki_14\n",
      "wiki_67\n",
      "wiki_25\n",
      "wiki_17\n",
      "wiki_18\n",
      "wiki_45\n",
      "wiki_26\n",
      "wiki_21\n",
      "wiki_34\n",
      "wiki_03\n",
      "wiki_02\n",
      "wiki_46\n",
      "wiki_28\n",
      "wiki_40\n",
      "wiki_36\n",
      "wiki_23\n",
      "wiki_42\n",
      "wiki_08\n",
      "wiki_11\n",
      "wiki_44\n",
      "wiki_48\n",
      "wiki_43\n",
      "wiki_31\n",
      "wiki_19\n",
      "wiki_29\n",
      "wiki_37\n",
      "wiki_39\n",
      "wiki_13\n",
      "wiki_47\n",
      "wiki_12\n",
      "wiki_32\n",
      "wiki_20\n",
      "wiki_27\n",
      "wiki_05\n",
      "wiki_35\n",
      "wiki_41\n",
      "wiki_38\n",
      "wiki_04\n",
      "wiki_30\n",
      "wiki_33\n",
      "wiki_07\n",
      "wiki_22\n",
      "wiki_00\n",
      "wiki_15\n",
      "wiki_16\n",
      "wiki_24\n",
      "wiki_01\n",
      "wiki_06\n",
      "wiki_09\n",
      "wiki_10\n",
      "wiki_14\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['observation'])\n",
    "\n",
    "path = 'text/'\n",
    "\n",
    "for directory in os.listdir(path):\n",
    "    directory = os.path.join(path, directory)\n",
    "    if os.path.isdir(directory):\n",
    "        for filename in os.listdir(directory):\n",
    "            print(filename)\n",
    "            with open(os.path.join(directory, filename)) as f:\n",
    "                soup = BeautifulSoup(f, \"html.parser\")\n",
    "                text = soup.get_text()\n",
    "                with open(os.path.join(directory, filename), \"w\") as f:\n",
    "                    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31min 49s, sys: 4min 52s, total: 36min 41s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "paths = ['azoscar.txt']\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:01:43.401518Z",
     "start_time": "2021-05-05T08:58:52.087303Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "deletable": false,
    "editable": false,
    "id": "IMnymRDLe0hi",
    "outputId": "4d26476f-e6b5-475a-a0c1-41b6fcdc041a",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "\n",
    "paths = [str(x) for x in glob.glob(r'text/**/*')]\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer()\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=paths, vocab_size=52_000, min_frequency=2, special_tokens=[\n",
    "    \"<s>\",\n",
    "    \"<pad>\",\n",
    "    \"</s>\",\n",
    "    \"<unk>\",\n",
    "    \"<mask>\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Ei7bqpRf1LH"
   },
   "source": [
    "Now let's save files to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‚ÄòazBERT‚Äô: File exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['azBERT/vocab.json', 'azBERT/merges.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir azBERT\n",
    "tokenizer.save_model(\"azBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:01:44.263553Z",
     "start_time": "2021-05-05T09:01:43.562035Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "deletable": false,
    "editable": false,
    "id": "EIS-irI0f32P",
    "outputId": "e86c4a24-eb65-4f0a-aa58-ed1931a05ac9",
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kazBERT/vocab.json', 'kazBERT/merges.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!mkdir kazBERT\n",
    "tokenizer.save_model(\"kazBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 ¬µs, sys: 6 ¬µs, total: 50 ¬µs\n",
      "Wall time: 61.3 ¬µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from pathlib import Path\n",
    "import glob\n",
    "from tokenizers import ByteLevelBPETokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:37:23.781202Z",
     "start_time": "2021-05-05T09:37:23.681037Z"
    },
    "id": "tKVWB8WShT-z"
   },
   "outputs": [],
   "source": [
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "\n",
    "\n",
    "tokenizer = ByteLevelBPETokenizer(\n",
    "    \"./azBERT/vocab.json\",\n",
    "    \"./azBERT/merges.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:37:23.817550Z",
     "start_time": "2021-05-05T09:37:23.782798Z"
    },
    "id": "hO5M3vrAhcuj"
   },
   "outputs": [],
   "source": [
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:37:23.902631Z",
     "start_time": "2021-05-05T09:37:23.820291Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "E3Ye27nchfzq",
    "outputId": "b9812ed2-1ecd-4e1b-d9bd-7de581955e70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=9, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"az…ôrtac x…ôb…ôr verir ki.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:37:23.982210Z",
     "start_time": "2021-05-05T09:37:23.904151Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "X8ya5_7rhjKS",
    "outputId": "e9e08ded-1081-4823-dd81-9d6be1255385"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'az', '√âƒªr', 'tac', 'ƒ†x√âƒªb√âƒªr', 'ƒ†verir', 'ƒ†ki', '.', '</s>']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"az…ôrtac x…ôb…ôr verir ki.\").tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:37:24.057407Z",
     "start_time": "2021-05-05T09:37:23.985009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' x…ôb…ôr'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tokenizers.decoders import ByteLevel\n",
    "decoder = ByteLevel()\n",
    "decoder.decode([ 'ƒ†x√âƒªb√âƒªr' ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQpUC_CDhnWW"
   },
   "source": [
    "## 3. Train a language model from scratch\n",
    "\n",
    "**Update:** This section follows along the [`run_language_modeling.py`](https://github.com/huggingface/transformers/blob/master/examples/legacy/run_language_modeling.py) script, using our new [`Trainer`](https://github.com/huggingface/transformers/blob/master/src/transformers/trainer.py) directly. Feel free to pick the approach you like best.\n",
    "\n",
    "> We‚Äôll train a RoBERTa-like model, which is a BERT-like with a couple of changes (check the [documentation](https://huggingface.co/transformers/model_doc/roberta.html) for more details).\n",
    "\n",
    "As the model is BERT-like, we‚Äôll train it on a task of *Masked language modeling*, i.e. the predict how to fill arbitrary tokens that we randomly mask in the dataset. This is taken care of by the example script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:37:26.285678Z",
     "start_time": "2021-05-05T09:37:24.060269Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "VNZZs-r6iKAV",
    "outputId": "c8404d6c-7662-4240-c8da-ee89edfaf51b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that PyTorch sees it\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u0qQzgrBi1OX"
   },
   "source": [
    "### We'll define the following config for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:37:26.657885Z",
     "start_time": "2021-05-05T09:37:26.287214Z"
    },
    "id": "LTXXutqeDzPi"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=52_000,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAwQ82JiE5pi"
   },
   "source": [
    "Now let's re-create our tokenizer in transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:37:26.858352Z",
     "start_time": "2021-05-05T09:37:26.660365Z"
    },
    "id": "4keFBUjQFOD1"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"./azBERT\", max_len=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yNCw-3hFv9h"
   },
   "source": [
    "Finally let's initialize our model.\n",
    "\n",
    "**Important:**\n",
    "\n",
    "As we are training from scratch, we only initialize from a config, not from an existing pretrained model or checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:37:29.364547Z",
     "start_time": "2021-05-05T09:37:26.861073Z"
    },
    "id": "BzMqR-dzF4Ro",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM\n",
    "\n",
    "model = RobertaForMaskedLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:37:29.371443Z",
     "start_time": "2021-05-05T09:37:29.367077Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jU6JhBSTKiaM",
    "outputId": "35879a60-2915-4894-f702-2d649cfa398a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83504416"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()\n",
    "# => 84 million parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBtUHRMliOLM"
   },
   "source": [
    "### Now let's build our training Dataset\n",
    "\n",
    "We'll build our dataset by applying our tokenizer to our text file.\n",
    "\n",
    "Here, as we only have one text file, we don't even need to customize our `Dataset`. We'll just use the `LineByLineDataset` out-of-the-box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:03:16.744621Z",
     "start_time": "2021-05-05T09:03:16.458677Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'azoscar.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b1af337a9aedfc0e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/denay/.cache/huggingface/datasets/text/default-b1af337a9aedfc0e/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /home/denay/.cache/huggingface/datasets/text/default-b1af337a9aedfc0e/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "paths = ['azoscar.txt']\n",
    "dataset = load_dataset('text', data_files=paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:03:31.041231Z",
     "start_time": "2021-05-05T09:03:19.938497Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0ac4a4a107fff5df\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/denay/.cache/huggingface/datasets/text/default-0ac4a4a107fff5df/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 tables [00:00, ? tables/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /home/denay/.cache/huggingface/datasets/text/default-0ac4a4a107fff5df/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "paths = [str(x) for x in glob.glob(r'text/**/*')]\n",
    "dataset = load_dataset('text', data_files=paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Psixologiya elmi q…ôdim tarix…ô malikdir. Psixoloji anlayƒ±≈ülar sistem ≈ü…ôklind…ô ilk d…ôf…ô olaraq Aristotelin (eramƒ±zdan …ôvv…ôl IV …ôsr) \"\"Ruh haqqƒ±nda\"\" traktatƒ±nda ≈ü…ôrh olunmu≈üdur. Traktat psixologiya yox, \"\"ruh haqqƒ±nda\"\" adlanƒ±r. Bu da t…ôsad√ºfi deyildir. Uzun m√ºdd…ôt (XIX …ôsrin sonlarƒ±na q…ôd…ôr) psixologiya elmi f…ôls…ôf…ôy…ô aid f…ônn hesab olunub. Avropa …ôd…ôbiyyatƒ±nda mental (latƒ±n s√∂z√º olub \"\"psixi olan\"\" dem…ôkdir) f…ôls…ôf…ô, ruhiyyat, pnevmatalogiya (pnevma ‚Äì yunan s√∂z√º olub n…ôf…ôs, ruh dem…ôkdir) adlandƒ±rƒ±lmƒ±≈ülar.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T08:41:10.176424Z",
     "start_time": "2021-05-05T08:41:10.129104Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '06.10.22 20:27 …ôrzind…ô olan d…ôyi≈üiklikl…ôr Yazan Azer 06.10.22 20:14'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 414 ms, sys: 74.9 ms, total: 489 ms\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from transformers import LineByLineTextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:43:54.154014Z",
     "start_time": "2021-05-05T09:37:29.372944Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "GlvP_A-THEEl",
    "outputId": "e0510a33-7937-4a04-fa1c-d4e20b758bb2"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataset = LineByLineTextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"azoscar.txt\",\n",
    "    block_size=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hDLs73HcIHk5"
   },
   "source": [
    "Like in the [`run_language_modeling.py`](https://github.com/huggingface/transformers/blob/master/examples/language-modeling/run_language_modeling.py) script, we need to define a data_collator.\n",
    "\n",
    "This is just a small helper that will help us batch different samples of the dataset together into an object that PyTorch knows how to perform backprop on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T11:36:48.540700Z",
     "start_time": "2021-05-12T11:36:48.468155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.data.datasets.language_modeling.LineByLineTextDataset at 0x7f3b6ecf3e80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:43:54.484473Z",
     "start_time": "2021-05-05T09:43:54.214963Z"
    },
    "id": "zTgWPa9Dipk2"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ri2BIQKqjfHm"
   },
   "source": [
    "### Finally, we are all set to initialize our Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T09:44:01.055690Z",
     "start_time": "2021-05-05T09:43:54.485848Z"
    },
    "id": "YpvnFFmZJD-N"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./azBERT\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_gpu_train_batch_size=32,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    prediction_loss_only=True,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6sASa36Nf-N"
   },
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T17:08:38.757186Z",
     "start_time": "2021-05-05T09:44:01.057479Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738,
     "referenced_widgets": [
      "a58a66392b644b1384661e850c077a6c",
      "a491e8caa0a048beb3b5259f14eb233f",
      "837c9ddc3d594e088891874560c646b8",
      "dbf50873d62c4ba39321faefbed0cca5",
      "40bf955ba0284e84b198da6be8654219",
      "fe20a8dae6e84628b5076d02183090f5",
      "93b3f9eae3cb4e3e859cf456e3547c6d",
      "6feb10aeb43147e6aba028d065947ae8",
      "0989d41a4da24e9ebff377e02127642c",
      "42c6061ef7e44f179db5a6e3551c0f17",
      "d295dd80550447d88da0f04ce36a22ff",
      "04e7e6d291da49d5816dc98a2904e95c",
      "e7d8c3a4fecd40778e32966b29ea65a1",
      "016d7c8318f742c1943464b08232a510",
      "8388e9da9da4492c98c19235ca5fc1b5",
      "39c23c6a972b419eb2eeeebafeaedc22"
     ]
    },
    "id": "VmaHZXzmkNtJ",
    "outputId": "a19880cb-bcc6-4885-bf24-c2c6d0f56d1e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "***** Running training *****\n",
      "  Num examples = 580217\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 27198\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='27198' max='27198' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [27198/27198 2:41:16, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.559800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.301400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>6.110400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>5.914800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.750700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.592600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>5.418400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>5.269900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>5.114300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>4.979900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>4.833600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>4.712800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>4.639900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>4.523300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>4.434700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>4.362500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>4.283500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>4.215300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>4.130500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>4.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>4.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.984200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>3.906500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.826100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>3.784400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.749100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>3.715300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>3.700900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>3.656100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>3.595800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>3.582200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>3.546800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>3.505300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>3.488600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>3.469200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>3.446000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>3.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>3.381900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>3.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>3.368300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>3.339200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>3.324900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>3.311700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>3.301700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>3.300600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>3.286900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>3.260200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>3.282100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>3.261900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>3.256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>3.246900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>3.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>3.237700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>3.220800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./azBERT/checkpoint-10000\n",
      "Configuration saved in ./azBERT/checkpoint-10000/config.json\n",
      "Model weights saved in ./azBERT/checkpoint-10000/pytorch_model.bin\n",
      "/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4h 39min 36s, sys: 2min 4s, total: 4h 41min 40s\n",
      "Wall time: 2h 41min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=27198, training_loss=4.05967112216575, metrics={'train_runtime': 9676.447, 'train_samples_per_second': 179.885, 'train_steps_per_second': 2.811, 'total_flos': 5.771438944918733e+16, 'train_loss': 4.05967112216575, 'epoch': 3.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZkooHz1-_2h"
   },
   "source": [
    "#### üéâ Save final model (+ tokenizer + config) to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T18:06:11.693131Z",
     "start_time": "2021-05-05T18:06:11.077443Z"
    },
    "id": "QDNgPls7_l13"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./azBERT\n",
      "Configuration saved in ./azBERT/config.json\n",
      "Model weights saved in ./azBERT/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(\"./azBERT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0caceCy_p1-"
   },
   "source": [
    "## 4. Check that the LM actually trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIQJ8ND_AEhl"
   },
   "source": [
    "Aside from looking at the training and eval losses going down, the easiest way to check whether our language model is learning anything interesting is via the `FillMaskPipeline`.\n",
    "\n",
    "Pipelines are simple wrappers around tokenizers and models, and the 'fill-mask' one will let you input a sequence containing a masked token (here, `<mask>`) and return a list of the most probable filled sequences, with their probabilities.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T18:06:17.852381Z",
     "start_time": "2021-05-05T18:06:13.767559Z"
    },
    "collapsed": true,
    "id": "ltXgXyCbAJLY",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./azBERT/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading configuration file ./azBERT/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading weights file ./azBERT/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForMaskedLM.\n",
      "\n",
      "All the weights of RobertaForMaskedLM were initialized from the model checkpoint at ./azBERT.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForMaskedLM for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file ./azBERT/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "Didn't find file ./azBERT/tokenizer.json. We won't load it.\n",
      "Didn't find file ./azBERT/added_tokens.json. We won't load it.\n",
      "Didn't find file ./azBERT/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./azBERT/tokenizer_config.json. We won't load it.\n",
      "loading file ./azBERT/vocab.json\n",
      "loading file ./azBERT/merges.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading configuration file ./azBERT/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading configuration file ./azBERT/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fill_mask = pipeline(\n",
    "    \"fill-mask\",\n",
    "    model=\"./azBERT\",\n",
    "    tokenizer=\"./azBERT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-05T18:25:22.591204Z",
     "start_time": "2021-05-05T18:25:22.455480Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "collapsed": true,
    "id": "UIvgZ3S6AO0z",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5f3d2f00-abdc-44a9-9c1b-75e3ec328576",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'az…ôrtac x…ôb…ôr verir ki',\n",
       "  'score': 0.9791690707206726,\n",
       "  'token': 1053,\n",
       "  'token_str': ' verir'},\n",
       " {'sequence': 'az…ôrtac x…ôb…ôr verib ki',\n",
       "  'score': 0.004408467561006546,\n",
       "  'token': 2313,\n",
       "  'token_str': ' verib'},\n",
       " {'sequence': 'az…ôrtac x…ôb…ôr yayƒ±b ki',\n",
       "  'score': 0.00216124439612031,\n",
       "  'token': 6580,\n",
       "  'token_str': ' yayƒ±b'},\n",
       " {'sequence': 'az…ôrtac x…ôb…ôr agentliyi ki',\n",
       "  'score': 0.0014381826622411609,\n",
       "  'token': 14711,\n",
       "  'token_str': ' agentliyi'},\n",
       " {'sequence': 'az…ôrtac x…ôb…ôraz ki',\n",
       "  'score': 0.0012858203845098615,\n",
       "  'token': 320,\n",
       "  'token_str': 'az'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(\"az…ôrtac x…ôb…ôr <mask> ki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'M…ôn…ô o yum≈üaq fransƒ±z bulkalarƒ±ndan daha √ßox ver',\n",
       "  'score': 0.5982716083526611,\n",
       "  'token': 716,\n",
       "  'token_str': ' daha'},\n",
       " {'sequence': 'M…ôn…ô o yum≈üaq fransƒ±z bulkalarƒ±ndan bir √ßox ver',\n",
       "  'score': 0.1061108186841011,\n",
       "  'token': 374,\n",
       "  'token_str': ' bir'},\n",
       " {'sequence': 'M…ôn…ô o yum≈üaq fransƒ±z bulkalarƒ±ndan biri √ßox ver',\n",
       "  'score': 0.05577299743890762,\n",
       "  'token': 1331,\n",
       "  'token_str': ' biri'},\n",
       " {'sequence': 'M…ôn…ô o yum≈üaq fransƒ±z bulkalarƒ±ndan …ôn √ßox ver',\n",
       "  'score': 0.029407601803541183,\n",
       "  'token': 745,\n",
       "  'token_str': ' …ôn'},\n",
       " {'sequence': 'M…ôn…ô o yum≈üaq fransƒ±z bulkalarƒ±ndan √ßox √ßox ver',\n",
       "  'score': 0.011952652595937252,\n",
       "  'token': 524,\n",
       "  'token_str': ' √ßox'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(\"M…ôn…ô o yum≈üaq fransƒ±z bulkalarƒ±ndan <mask> √ßox ver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'Az…ôrbaycan Ordusunun m√∂vqel…ôri artilleriya at…ô≈üin…ô m…ôruz qalƒ±r',\n",
       "  'score': 0.23799513280391693,\n",
       "  'token': 29362,\n",
       "  'token_str': ' at…ô≈üin…ô'},\n",
       " {'sequence': 'Az…ôrbaycan Ordusunun m√∂vqel…ôri artilleriya h√ºcumuna m…ôruz qalƒ±r',\n",
       "  'score': 0.059697140008211136,\n",
       "  'token': 35291,\n",
       "  'token_str': ' h√ºcumuna'},\n",
       " {'sequence': 'Az…ôrbaycan Ordusunun m√∂vqel…ôri artilleriya at…ô≈ü…ô m…ôruz qalƒ±r',\n",
       "  'score': 0.023507563397288322,\n",
       "  'token': 5703,\n",
       "  'token_str': ' at…ô≈ü…ô'},\n",
       " {'sequence': 'Az…ôrbaycan Ordusunun m√∂vqel…ôri artilleriya silahlardan m…ôruz qalƒ±r',\n",
       "  'score': 0.015011416748166084,\n",
       "  'token': 32201,\n",
       "  'token_str': ' silahlardan'},\n",
       " {'sequence': 'Az…ôrbaycan Ordusunun m√∂vqel…ôri artilleriya q√ºvv…ôl…ôrinin m…ôruz qalƒ±r',\n",
       "  'score': 0.014030301943421364,\n",
       "  'token': 7886,\n",
       "  'token_str': ' q√ºvv…ôl…ôrinin'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_mask(\"Az…ôrbaycan Ordusunun m√∂vqel…ôri artilleriya <mask> m…ôruz qalƒ±r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pickle.load(open( \"./dataset1.p\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 144074\n",
      "  Batch size = 16\n",
      "/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9005' max='9005' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9005/9005 04:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Using deprecated `--per_gpu_train_batch_size` argument which will be removed in a future version. Using `--per_device_train_batch_size` is preferred.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdeviloper\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">./kazBERT</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/deviloper/huggingface\" target=\"_blank\">https://wandb.ai/deviloper/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/deviloper/huggingface/runs/3c13vtqj\" target=\"_blank\">https://wandb.ai/deviloper/huggingface/runs/3c13vtqj</a><br/>\n",
       "                Run data is saved locally in <code>/home/ubuntu/ATABA/src/kazBert/wandb/run-20210908_105013-3c13vtqj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.30222225189209, 'eval_runtime': 262.9688, 'eval_samples_per_second': 547.875, 'eval_steps_per_second': 34.244}\n"
     ]
    }
   ],
   "source": [
    "metrics=trainer.evaluate(dataset1)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/parsers.py\", line 2157, in read\n",
      "    data = self._reader.read(nrows)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 847, in pandas._libs.parsers.TextReader.read\n",
      "  File \"pandas/_libs/parsers.pyx\", line 862, in pandas._libs.parsers.TextReader._read_low_memory\n",
      "  File \"pandas/_libs/parsers.pyx\", line 941, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"pandas/_libs/parsers.pyx\", line 1073, in pandas._libs.parsers.TextReader._convert_column_data\n",
      "  File \"pandas/_libs/parsers.pyx\", line 1119, in pandas._libs.parsers.TextReader._convert_tokens\n",
      "  File \"pandas/_libs/parsers.pyx\", line 1162, in pandas._libs.parsers.TextReader._convert_with_dtype\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/core/dtypes/common.py\", line 530, in is_categorical_dtype\n",
      "    def is_categorical_dtype(arr_or_dtype) -> bool:\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-101-6c7334262542>\", line 2, in <module>\n",
      "    df = pd.read_csv('/home/denay/azer-bert/azertag_sentences_with_categories.csv')\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/parsers.py\", line 688, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/parsers.py\", line 460, in _read\n",
      "    data = parser.read(nrows)\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/parsers.py\", line 1198, in read\n",
      "    ret = self._engine.read(nrows)\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/parsers.py\", line 2157, in read\n",
      "    data = self._reader.read(nrows)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1452, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/tokenize.py\", line 454, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/tokenize.py\", line 423, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/home/ubuntu/.virtualenvs/ml/lib/python3.6/tokenize.py\", line 381, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-101-6c7334262542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/denay/azer-bert/azertag_sentences_with_categories.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0;32m-> 1211\u001b[0;31m                                                                      chained_exceptions_tb_offset)\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/denay/azer-bert/azertag_sentences_with_categories.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-00fbab3f4ac620d9\n",
      "Reusing dataset csv (/home/denay/.cache/huggingface/datasets/csv/default-00fbab3f4ac620d9/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c29fbd424a245d3bf72fe04de1ca147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files='/home/denay/azer-bert/azertag_sentences_with_categories.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-7dee9403f089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pandas\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/denay/azer-bert/merged_neural.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# dataset = dataset['train']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# dataset = dataset.rename_column(\"content\", \"text\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, **config_kwargs)\u001b[0m\n\u001b[1;32m   1732\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m         \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1734\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mconfig_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1735\u001b[0m     )\n\u001b[1;32m   1736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, use_auth_token, **config_kwargs)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m         \u001b[0mdata_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m     )\n\u001b[1;32m   1508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, **download_kwargs)\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0mdata_files\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m             \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m         ).get_module()\n\u001b[1;32m   1155\u001b[0m     \u001b[0;31m# Try locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/load.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, data_dir, data_files, download_config, download_mode)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0mincrease_load_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDatasetModule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mincrease_load_count\u001b[0;34m(name, resource_type)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHF_DATASETS_OFFLINE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHF_UPDATE_DOWNLOAD_COUNTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mhead_hf_s3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".py\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36mhead_hf_s3\u001b[0;34m(identifier, filename, use_cdn, dataset, max_retries)\u001b[0m\n\u001b[1;32m     93\u001b[0m     return http_head(\n\u001b[1;32m     94\u001b[0m         \u001b[0mhf_bucket_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cdn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cdn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36mhttp_head\u001b[0;34m(url, proxies, headers, cookies, allow_redirects, timeout, max_retries)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m     )\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/utils/file_utils.py\u001b[0m in \u001b[0;36m_request_with_retry\u001b[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, **params)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mtries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    527\u001b[0m         }\n\u001b[1;32m    528\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m                 )\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    675\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m             )\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             conn = connection.create_connection(\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m             )\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"pandas\", data_files=\"/home/denay/azer-bert/merged_neural.pkl\")\n",
    "# dataset = dataset['train']\n",
    "# dataset = dataset.rename_column(\"content\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text'],\n",
       "        num_rows: 3492453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns([\"url\", \"news_id\",'order_number','sub_category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Column name text_az not in the dataset. Current columns in the dataset: ['url', 'category', 'sub_category', 'news_id', 'order_number', 'text_content']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-799fc2ccc5f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"url\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"news_id\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'order_number'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sub_category'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'text_az'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'text_en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__index_level_0__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36mremove_columns\u001b[0;34m(self, column_names)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_values_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrename_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_column_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_column_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m    337\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_values_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDatasetDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrename_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_column_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_column_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Dataset\"\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"self\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m         }\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# apply actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"DatasetDict\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Dataset\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;31m# re-apply format to the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/fingerprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0;31m# Call actual function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0;31m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mremove_columns\u001b[0;34m(self, column_names, new_fingerprint)\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcolumn_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m                 raise ValueError(\n\u001b[0;32m-> 1636\u001b[0;31m                     \u001b[0;34mf\"Column name {column_name} not in the dataset. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1637\u001b[0m                     \u001b[0;34mf\"Current columns in the dataset: {dataset._data.column_names}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: Column name text_az not in the dataset. Current columns in the dataset: ['url', 'category', 'sub_category', 'news_id', 'order_number', 'text_content']"
     ]
    }
   ],
   "source": [
    "dataset = dataset.remove_columns([\"url\", \"news_id\",'order_number','sub_category','text_az', 'text_en', '__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['text_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"category\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.rename_column(\"text_az_lower\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'text'],\n",
       "    num_rows: 5480028\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"C∆èMƒ∞YY∆èT\": 0, \"R∆èSMƒ∞ XRONƒ∞KA\": 1, \"ƒ∞QTƒ∞SADƒ∞YYAT\": 2, \"R∆èSMƒ∞ S∆èN∆èDL∆èR\": 3, \"ELM V∆è T∆èHSƒ∞L\": 4, \"REGƒ∞ONLAR\": 5, \"Sƒ∞YAS∆èT\": 6, \"M∆èD∆èNƒ∞YY∆èT\": 7, \"QAN YADDA≈ûI\": 8, \"D√úNYA\": 9, \"ƒ∞DMAN\": 10, \"C√úMHURƒ∞YY∆èT - 100\": 11, \"M√úSAHƒ∞B∆è\":12, \"BA≈û X∆èB∆èRL∆èR\":13, \"≈ûU≈ûA ƒ∞Lƒ∞\":14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"./azBERT\", max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    tokenized_batch = tokenizer(batch['text'], padding='max_length', truncation=True, max_length=128)\n",
    "    tokenized_batch[\"labels\"] = [label2id[label] for label in batch[\"labels\"]]\n",
    "    return tokenized_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a0a629f30e48f6848e21011d5ba1df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3493 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = dataset.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.save_to_disk('datasets-original-tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.save_to_disk('datasets-tokenized-max-length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3492453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk('datasets-tokenized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk('datasets-stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb09bbc57ae64bf9ace2f4cd7fe0e12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/3493 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c54b5011b0b498fb7017955f5c6e3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/3493 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b12d31f61574bc182a52e5834738861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/350 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = datasets.class_encode_column('labels', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc74476fd0014ceb84e6072f80a17752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/280 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca672955ebff420c9a89bb34e8a47b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/70 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets = datasets.cast_column(\"labels\", ClassLabel(num_classes=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = datasets['train'].train_test_split(test_size=0.2, stratify_by_column='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927fdac9eab747059db5bb102d0d0fac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/2794 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f558bd0f7da74a60bc6a0c814dd51e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/699 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasets.save_to_disk('datasets-original-stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     171922\n",
       "1     115095\n",
       "7      69454\n",
       "8      54111\n",
       "9      43322\n",
       "10     25692\n",
       "11     25599\n",
       "12     21761\n",
       "13     19127\n",
       "14      7380\n",
       "2       4435\n",
       "3        835\n",
       "4         37\n",
       "5         17\n",
       "6          6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(np.array(datasets['test']['labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.save_to_disk('datasets-stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_old = load_from_disk('datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iÃáyunun 22-d…ô az…ôrbaycan respublikasƒ±nƒ±n prezidenti iÃálham …ôliyev v…ô √∂zb…ôkistan respublikasƒ±nƒ±n prezidenti ≈üavkat mirziyoyev xiv…ô ≈ü…ôh…ôrind…ô ‚Äúnurullaboy‚Äù saray kompleksi il…ô tanƒ±≈ü olublar.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets_old['test'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f…ôaliyy…ôt qurulu≈üunun bir par√ßasƒ± olaraq d√∂vl…ôt binasƒ±nƒ±n √∂n√ºnd…ôki yerd…ô sipressl…ôrin qoyuldu'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['test'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2235169\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 558793\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./azBERT were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ./azBERT and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./azBERT\", num_labels=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_WATCH\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"./azBERT\", max_len=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the training set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running training *****\n",
      "  Num examples = 2793962\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 174624\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miamdenay\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">classifier-original-strat-no-collator</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/iamdenay/huggingface\" target=\"_blank\">https://wandb.ai/iamdenay/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/iamdenay/huggingface/runs/3qoirnke\" target=\"_blank\">https://wandb.ai/iamdenay/huggingface/runs/3qoirnke</a><br/>\n",
       "                Run data is saved locally in <code>/home/denay/azer-bert/wandb/run-20230731_212904-3qoirnke</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61678' max='174624' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 61678/174624 2:04:22 < 3:47:45, 8.26 it/s, Epoch 0.71/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"classifier-original-strat-no-collator\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=datasets[\"train\"],\n",
    "    eval_dataset=datasets[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    # data_collator=data_collator,\n",
    "    # compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `RobertaForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1096006\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-f245b31d31e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2056\u001b[0m             \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2058\u001b[0;31m             \u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2059\u001b[0m         )\n\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2222\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2223\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2225\u001b[0m             \u001b[0;31m# Update containers on host\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   2425\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2426\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2427\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2428\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2429\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   1819\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1821\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1822\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to classifier-original-strat-no-collator\n",
      "Configuration saved in classifier-original-strat-no-collator/config.json\n",
      "Model weights saved in classifier-original-strat-no-collator/pytorch_model.bin\n",
      "tokenizer config file saved in classifier-original-strat-no-collator/tokenizer_config.json\n",
      "Special tokens file saved in classifier-original-strat-no-collator/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('classifier-original-strat-no-collator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./classifier-original-strat-no-collator/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"./azBERT\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading configuration file ./classifier-original-strat-no-collator/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"./azBERT\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading weights file ./classifier-original-strat-no-collator/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at ./classifier-original-strat-no-collator.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file ./azBERT/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "Didn't find file ./azBERT/tokenizer.json. We won't load it.\n",
      "Didn't find file ./azBERT/added_tokens.json. We won't load it.\n",
      "Didn't find file ./azBERT/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./azBERT/tokenizer_config.json. We won't load it.\n",
      "loading file ./azBERT/vocab.json\n",
      "loading file ./azBERT/merges.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading configuration file ./azBERT/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n",
      "loading configuration file ./azBERT/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.10.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 52000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'max_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-7273bd918f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"text-classification\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./classifier-original-strat-no-collator\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"./azBERT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m  \u001b[0;31m#\"./azBERT\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, framework, revision, use_fast, use_auth_token, model_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"feature_extractor\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtask_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/pipelines/text_classification.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, return_all_scores, function_to_apply, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_all_scores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_to_apply\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         self.check_model_type(\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'max_length'"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\n",
    "    \"text-classification\",\n",
    "    model=\"./classifier-original-strat-no-collator\",\n",
    "    tokenizer= \"./azBERT\", max_length=512, truncation=True  #\"./azBERT\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-592b55a8930a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_collator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         )\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"label\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, return_attention_mask, return_tensors, verbose)\u001b[0m\n\u001b[1;32m   2745\u001b[0m                 \u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2746\u001b[0m             )\n\u001b[0;32m-> 2747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2749\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequired_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepend_batch_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mconvert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    720\u001b[0m                     )\n\u001b[1;32m    721\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 722\u001b[0;31m                     \u001b[0;34m\"Unable to create tensor, you should probably activate truncation and/or padding \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m                     \u001b[0;34m\"with 'padding=True' 'truncation=True' to have batched tensors with the same length.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                 )\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create tensor, you should probably activate truncation and/or padding with 'padding=True' 'truncation=True' to have batched tensors with the same length."
     ]
    }
   ],
   "source": [
    "data_collator(datasets['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': 13,\n",
       " 'text': 'm…ôrasimd…ô s√∂z alanlar milli lider heydar reylyevin tragediyanƒ±n g√ºnahkarlarƒ±nƒ± a√ßƒ±qlamasƒ±na, bu qanalarƒ±n katliamlarƒ±nƒ± siyasi v…ô hukuki a√ßƒ±dan deƒüerlendirm…ôy…ô v…ô ≈üehitl…ôrin adlarƒ±nƒ± davam ettirm…ôy…ô xidm…ôtin…ô b√∂y√ºk t…ô≈ü…ôkk√ºr ettiler.',\n",
       " 'input_ids': [0,\n",
       "  2655,\n",
       "  7939,\n",
       "  270,\n",
       "  1004,\n",
       "  21314,\n",
       "  1815,\n",
       "  3522,\n",
       "  1398,\n",
       "  583,\n",
       "  17263,\n",
       "  80,\n",
       "  1821,\n",
       "  264,\n",
       "  283,\n",
       "  14627,\n",
       "  437,\n",
       "  1182,\n",
       "  16117,\n",
       "  1069,\n",
       "  5402,\n",
       "  1553,\n",
       "  16,\n",
       "  449,\n",
       "  1081,\n",
       "  2771,\n",
       "  2282,\n",
       "  298,\n",
       "  312,\n",
       "  1069,\n",
       "  2063,\n",
       "  304,\n",
       "  301,\n",
       "  2657,\n",
       "  14413,\n",
       "  1173,\n",
       "  383,\n",
       "  1373,\n",
       "  295,\n",
       "  303,\n",
       "  51176,\n",
       "  1026,\n",
       "  304,\n",
       "  357,\n",
       "  708,\n",
       "  368,\n",
       "  536,\n",
       "  17875,\n",
       "  1181,\n",
       "  379,\n",
       "  821,\n",
       "  1026,\n",
       "  17075,\n",
       "  832,\n",
       "  4919,\n",
       "  379,\n",
       "  88,\n",
       "  15172,\n",
       "  18,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['test'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./classifier-original-strat-no-collator\", num_labels=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['test'][0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[  2.2476,   2.8794,  -3.2040,  -4.7832,  -6.0020,  -7.9419, -10.1485,\n",
       "           3.8386,   6.0702,  -0.2575,  -1.5031,  -0.4337,  -0.7097,  -2.5050,\n",
       "          -3.0035],\n",
       "        [  1.3702,   3.9130,  -3.5998,  -4.8467,  -6.5749,  -7.5954,  -9.5198,\n",
       "           1.2158,   5.7206,   0.0210,  -0.7157,   0.0716,   0.1507,  -2.2955,\n",
       "          -1.3261]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([datasets['test'][0]['input_ids'], datasets['test'][0]['attention_mask']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model(torch.tensor([datasets['test'][0]['input_ids'], datasets['test'][0]['attention_mask']])).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.add(x[0], x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = load_from_disk('datasets-original-stratified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_test = ds['test'].with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(ds_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'labels': tensor([ 8, 10,  9,  1,  1, 10,  1,  8,  8,  1,  7, 13,  0,  1,  0,  1,  7,  0,\n",
      "         1,  0,  0,  0,  7,  7, 13,  0, 11,  1,  0,  0,  0,  7]), 'input_ids': tensor([[    0,   681,   990,  ...,     1,     1,     1],\n",
      "        [    0,  3084,   522,  ...,     1,     1,     1],\n",
      "        [    0,    17,   271,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,  5348,   451,  ...,     1,     1,     1],\n",
      "        [    0,  5348,  8220,  ...,     1,     1,     1],\n",
      "        [    0, 36879,  2254,  ...,     1,     1,     1]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "for x in dataloader:\n",
    "    print(x)  # model(torch.tensor())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21828/21828 [1:30:57<00:00,  4.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "preds = []\n",
    "labels = []\n",
    "for batch in tqdm.tqdm(dataloader):\n",
    "    p = model(batch['input_ids'], batch['attention_mask']).logits\n",
    "    preds.extend(torch.argmax(p, dim=1))\n",
    "    labels.extend(batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(ds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.81      0.85    193116\n",
      "           1       0.79      0.89      0.84    101645\n",
      "           2       0.87      0.91      0.89     46975\n",
      "           3       0.65      0.79      0.71      7654\n",
      "           4       0.41      0.68      0.51       248\n",
      "           5       0.04      1.00      0.07         7\n",
      "           6       0.24      0.89      0.38        19\n",
      "           7       0.85      0.82      0.83     72168\n",
      "           8       0.94      0.92      0.93     55236\n",
      "           9       0.75      0.77      0.76     42378\n",
      "          10       0.80      0.88      0.84     23430\n",
      "          11       0.58      0.66      0.62     22234\n",
      "          12       0.76      0.77      0.76     21400\n",
      "          13       0.97      0.90      0.93    228229\n",
      "          14       0.74      0.97      0.84     62066\n",
      "\n",
      "    accuracy                           0.86    876805\n",
      "   macro avg       0.69      0.84      0.72    876805\n",
      "weighted avg       0.87      0.86      0.86    876805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(preds, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier(\n",
    "    \"Az…ôrbaycan Ordusunun m√∂vqel…ôri artilleriya at…ô≈üin…ô m…ôruz qalƒ±r\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier(\n",
    "    datasets['test']['text']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 5, 1, 0, 5, 2, 2, 0, 0, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['test']['labels'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 10,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 10,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 3,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 10,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 3,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 0,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 10,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 10,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 2,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['test']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textaugment import EDA\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/denay/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = EDA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an official lunch was given in pureness of pakistani prime minister on behalf of the president of azerbaijan\n"
     ]
    }
   ],
   "source": [
    "output = t.synonym_replacement('An official lunch was given in honor of Pakistani Prime Minister on behalf of the President of Azerbaijan'.lower())\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {\"C∆èMƒ∞YY∆èT\": 0, \"R∆èSMƒ∞ XRONƒ∞KA\": 1, \"ƒ∞QTƒ∞SADƒ∞YYAT\": 2, \"R∆èSMƒ∞ S∆èN∆èDL∆èR\": 3, \"ELM V∆è T∆èHSƒ∞L\": 4, \"REGƒ∞ONLAR\": 5, \"Sƒ∞YAS∆èT\": 6, \"M∆èD∆èNƒ∞YY∆èT\": 7, \"QAN YADDA≈ûI\": 8, \"D√úNYA\": 9, \"ƒ∞DMAN\": 10, \"C√úMHURƒ∞YY∆èT - 100\": 11, \"M√úSAHƒ∞B∆è\":12, \"BA≈û X∆èB∆èRL∆èR\":13, \"≈ûU≈ûA ƒ∞Lƒ∞\":14}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = dict((v, k) for k, v in label2id.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_for_aug = [id2label[x] for x in [8,9,10,11,12,13, 14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/denay/azer-bert/azertag_sentences_with_categories.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_for_augmentation = df[df['category'].str.contains('|'.join(labels_for_aug))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>news_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1208432</th>\n",
       "      <td>https://azertag.az/xeber/Tarixine_sahib_chixan...</td>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>cumhuriyyet</td>\n",
       "      <td>63610</td>\n",
       "      <td>1</td>\n",
       "      <td>≈û…ômkird…ôki Heyd…ôr ∆èliyev M…ôrk…ôzind…ô Az…ôrbaycan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208433</th>\n",
       "      <td>https://azertag.az/xeber/Tarixine_sahib_chixan...</td>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>cumhuriyyet</td>\n",
       "      <td>63610</td>\n",
       "      <td>2</td>\n",
       "      <td>Konfransda ≈û…ômkir Rayon ƒ∞cra Hakimiyy…ôtinin ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208434</th>\n",
       "      <td>https://azertag.az/xeber/Tarixine_sahib_chixan...</td>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>cumhuriyyet</td>\n",
       "      <td>63610</td>\n",
       "      <td>3</td>\n",
       "      <td>AZ∆èRTAC-ƒ±n b√∂lg…ô m√ºxbiri x…ôb…ôr verir ki, konfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208435</th>\n",
       "      <td>https://azertag.az/xeber/Tarixine_sahib_chixan...</td>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>cumhuriyyet</td>\n",
       "      <td>63610</td>\n",
       "      <td>4</td>\n",
       "      <td>Sonra Heyd…ôr ∆èliyev M…ôrk…ôzinin foyesind…ô AMEA-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208436</th>\n",
       "      <td>https://azertag.az/xeber/Tarixine_sahib_chixan...</td>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>cumhuriyyet</td>\n",
       "      <td>63610</td>\n",
       "      <td>5</td>\n",
       "      <td>T…ôdbir i≈ütirak√ßƒ±larƒ± s…ôrgid…ô tariximizi …ôks et...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492422</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>73</td>\n",
       "      <td>Bu is…ô √∂zl√ºy√ºnd…ô XX …ôsr tariximizd…ô yeni-yeni ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492423</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>74</td>\n",
       "      <td>1998-ci ild…ôn b…ôri respublikamƒ±zda 31 mart h…ôr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492424</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>75</td>\n",
       "      <td>Bu hadis…ôl…ôri, onlarƒ±n d…ôrsl…ôrini unutmaƒüa haq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492425</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>76</td>\n",
       "      <td>Tarix he√ß zaman unudulmur, h…ôm d…ô yazƒ±lƒ±r.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492426</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>77</td>\n",
       "      <td>Erm…ôni v…ôh≈üilikl…ôri Az…ôrbaycan tarixinin qanla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198990 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       url           category  \\\n",
       "1208432  https://azertag.az/xeber/Tarixine_sahib_chixan...  C√úMHURƒ∞YY∆èT - 100   \n",
       "1208433  https://azertag.az/xeber/Tarixine_sahib_chixan...  C√úMHURƒ∞YY∆èT - 100   \n",
       "1208434  https://azertag.az/xeber/Tarixine_sahib_chixan...  C√úMHURƒ∞YY∆èT - 100   \n",
       "1208435  https://azertag.az/xeber/Tarixine_sahib_chixan...  C√úMHURƒ∞YY∆èT - 100   \n",
       "1208436  https://azertag.az/xeber/Tarixine_sahib_chixan...  C√úMHURƒ∞YY∆èT - 100   \n",
       "...                                                    ...                ...   \n",
       "3492422  https://azertag.az/xeber/31_mart___azerbaycanl...        QAN YADDA≈ûI   \n",
       "3492423  https://azertag.az/xeber/31_mart___azerbaycanl...        QAN YADDA≈ûI   \n",
       "3492424  https://azertag.az/xeber/31_mart___azerbaycanl...        QAN YADDA≈ûI   \n",
       "3492425  https://azertag.az/xeber/31_mart___azerbaycanl...        QAN YADDA≈ûI   \n",
       "3492426  https://azertag.az/xeber/31_mart___azerbaycanl...        QAN YADDA≈ûI   \n",
       "\n",
       "                   sub_category  news_id  order_number  \\\n",
       "1208432             cumhuriyyet    63610             1   \n",
       "1208433             cumhuriyyet    63610             2   \n",
       "1208434             cumhuriyyet    63610             3   \n",
       "1208435             cumhuriyyet    63610             4   \n",
       "1208436             cumhuriyyet    63610             5   \n",
       "...                         ...      ...           ...   \n",
       "3492422  bloody_memory_31_march   317210            73   \n",
       "3492423  bloody_memory_31_march   317210            74   \n",
       "3492424  bloody_memory_31_march   317210            75   \n",
       "3492425  bloody_memory_31_march   317210            76   \n",
       "3492426  bloody_memory_31_march   317210            77   \n",
       "\n",
       "                                              text_content  \n",
       "1208432  ≈û…ômkird…ôki Heyd…ôr ∆èliyev M…ôrk…ôzind…ô Az…ôrbaycan...  \n",
       "1208433  Konfransda ≈û…ômkir Rayon ƒ∞cra Hakimiyy…ôtinin ba...  \n",
       "1208434  AZ∆èRTAC-ƒ±n b√∂lg…ô m√ºxbiri x…ôb…ôr verir ki, konfr...  \n",
       "1208435  Sonra Heyd…ôr ∆èliyev M…ôrk…ôzinin foyesind…ô AMEA-...  \n",
       "1208436  T…ôdbir i≈ütirak√ßƒ±larƒ± s…ôrgid…ô tariximizi …ôks et...  \n",
       "...                                                    ...  \n",
       "3492422  Bu is…ô √∂zl√ºy√ºnd…ô XX …ôsr tariximizd…ô yeni-yeni ...  \n",
       "3492423  1998-ci ild…ôn b…ôri respublikamƒ±zda 31 mart h…ôr...  \n",
       "3492424  Bu hadis…ôl…ôri, onlarƒ±n d…ôrsl…ôrini unutmaƒüa haq...  \n",
       "3492425         Tarix he√ß zaman unudulmur, h…ôm d…ô yazƒ±lƒ±r.  \n",
       "3492426  Erm…ôni v…ôh≈üilikl…ôri Az…ôrbaycan tarixinin qanla...  \n",
       "\n",
       "[198990 rows x 6 columns]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from checkpoints import checkpoints\n",
    "checkpoints.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_for_augmentation['text_en'] = df_for_augmentation['text_content'].safe_map(translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_augmentation.to_pickle('en_for_aug.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = df_for_augmentation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check['text_en'] = checkpoints.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check.to_pickle('df_check_165922.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It is known that dinosaurs were destroyed by this meteorite impact and mammals started to develop.'"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_augmentation['text_en'].reset_index()['text_en'][34523]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_augmentation[['category','text_en']].to_csv('for_eda.tsv',sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3448904    86\n",
       "3439067    85\n",
       "3420454    80\n",
       "3389276    74\n",
       "3298084    73\n",
       "           ..\n",
       "3363924     0\n",
       "3307782     0\n",
       "3391407     0\n",
       "1210064     0\n",
       "3359672     0\n",
       "Name: text_en, Length: 198990, dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_augmentation['text_en'].str.findall(r'[^a-zA-Z0-9 ]').str.len().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_for_augmentation.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['non-alpha'] = test_df['text_en'].str.findall(r'[^a-zA-Z ]').str.len().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['len'] = test_df['text_en'].str.len().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>news_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>text_content</th>\n",
       "      <th>text_en</th>\n",
       "      <th>non-alpha</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3322582</th>\n",
       "      <td>https://azertag.az/xeber/Bacariqsiz_dahiler-82...</td>\n",
       "      <td>D√úNYA</td>\n",
       "      <td>oddly_enough</td>\n",
       "      <td>303753</td>\n",
       "      <td>17</td>\n",
       "      <td>10.</td>\n",
       "      <td>10.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334980</th>\n",
       "      <td>https://azertag.az/xeber/Dekabr_ayi_uchun_Fran...</td>\n",
       "      <td>D√úNYA</td>\n",
       "      <td>oddly_enough</td>\n",
       "      <td>304646</td>\n",
       "      <td>49</td>\n",
       "      <td>....</td>\n",
       "      <td>....</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356560</th>\n",
       "      <td>https://azertag.az/xeber/Masallinin_Sirebil_ke...</td>\n",
       "      <td>D√úNYA</td>\n",
       "      <td>oddly_enough</td>\n",
       "      <td>306324</td>\n",
       "      <td>10</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399018</th>\n",
       "      <td>https://azertag.az/xeber/IRALI_Ictimai_Birliyi...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_20_january</td>\n",
       "      <td>309886</td>\n",
       "      <td>4</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399056</th>\n",
       "      <td>https://azertag.az/xeber/Meksikanin_iki_en_nuf...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_20_january</td>\n",
       "      <td>309889</td>\n",
       "      <td>8</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490865</th>\n",
       "      <td>https://azertag.az/xeber/YASAMAL_RAYONUNDA_MAR...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317095</td>\n",
       "      <td>9</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491473</th>\n",
       "      <td>https://azertag.az/xeber/Susa_teatri_Sumqayit_...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317138</td>\n",
       "      <td>16</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491551</th>\n",
       "      <td>https://azertag.az/xeber/Zaqatalada_Azerbaycan...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317146</td>\n",
       "      <td>13</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491986</th>\n",
       "      <td>https://azertag.az/xeber/Ankara_Il_qezeti_bir_...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317184</td>\n",
       "      <td>5</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492029</th>\n",
       "      <td>https://azertag.az/xeber/Kiyevde_azerbaycanlil...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317189</td>\n",
       "      <td>7</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>232 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       url     category  \\\n",
       "3322582  https://azertag.az/xeber/Bacariqsiz_dahiler-82...        D√úNYA   \n",
       "3334980  https://azertag.az/xeber/Dekabr_ayi_uchun_Fran...        D√úNYA   \n",
       "3356560  https://azertag.az/xeber/Masallinin_Sirebil_ke...        D√úNYA   \n",
       "3399018  https://azertag.az/xeber/IRALI_Ictimai_Birliyi...  QAN YADDA≈ûI   \n",
       "3399056  https://azertag.az/xeber/Meksikanin_iki_en_nuf...  QAN YADDA≈ûI   \n",
       "...                                                    ...          ...   \n",
       "3490865  https://azertag.az/xeber/YASAMAL_RAYONUNDA_MAR...  QAN YADDA≈ûI   \n",
       "3491473  https://azertag.az/xeber/Susa_teatri_Sumqayit_...  QAN YADDA≈ûI   \n",
       "3491551  https://azertag.az/xeber/Zaqatalada_Azerbaycan...  QAN YADDA≈ûI   \n",
       "3491986  https://azertag.az/xeber/Ankara_Il_qezeti_bir_...  QAN YADDA≈ûI   \n",
       "3492029  https://azertag.az/xeber/Kiyevde_azerbaycanlil...  QAN YADDA≈ûI   \n",
       "\n",
       "                     sub_category  news_id  order_number text_content text_en  \\\n",
       "3322582              oddly_enough   303753            17          10.     10.   \n",
       "3334980              oddly_enough   304646            49         ....    ....   \n",
       "3356560              oddly_enough   306324            10       ######  ######   \n",
       "3399018  bloody_memory_20_january   309886             4       ######  ######   \n",
       "3399056  bloody_memory_20_january   309889             8       ######  ######   \n",
       "...                           ...      ...           ...          ...     ...   \n",
       "3490865    bloody_memory_31_march   317095             9       ######  ######   \n",
       "3491473    bloody_memory_31_march   317138            16       ######  ######   \n",
       "3491551    bloody_memory_31_march   317146            13       ######  ######   \n",
       "3491986    bloody_memory_31_march   317184             5       ######  ######   \n",
       "3492029    bloody_memory_31_march   317189             7       ######  ######   \n",
       "\n",
       "         non-alpha  len  \n",
       "3322582          3    3  \n",
       "3334980          4    4  \n",
       "3356560          6    6  \n",
       "3399018          6    6  \n",
       "3399056          6    6  \n",
       "...            ...  ...  \n",
       "3490865          6    6  \n",
       "3491473          6    6  \n",
       "3491551          6    6  \n",
       "3491986          6    6  \n",
       "3492029          6    6  \n",
       "\n",
       "[232 rows x 9 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['len']==test_df['non-alpha']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[~(test_df['len']==test_df['non-alpha'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>news_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>text_content</th>\n",
       "      <th>text_en</th>\n",
       "      <th>non-alpha</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1208432</th>\n",
       "      <td>https://azertag.az/xeber/Tarixine_sahib_chixan...</td>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>cumhuriyyet</td>\n",
       "      <td>63610</td>\n",
       "      <td>1</td>\n",
       "      <td>≈û…ômkird…ôki Heyd…ôr ∆èliyev M…ôrk…ôzind…ô Az…ôrbaycan...</td>\n",
       "      <td>A scientific-practical conference dedicated to...</td>\n",
       "      <td>5</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208433</th>\n",
       "      <td>https://azertag.az/xeber/Tarixine_sahib_chixan...</td>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>cumhuriyyet</td>\n",
       "      <td>63610</td>\n",
       "      <td>2</td>\n",
       "      <td>Konfransda ≈û…ômkir Rayon ƒ∞cra Hakimiyy…ôtinin ba...</td>\n",
       "      <td>At the conference, Alimpasha Mammadov, Head of...</td>\n",
       "      <td>21</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208434</th>\n",
       "      <td>https://azertag.az/xeber/Tarixine_sahib_chixan...</td>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>cumhuriyyet</td>\n",
       "      <td>63610</td>\n",
       "      <td>3</td>\n",
       "      <td>AZ∆èRTAC-ƒ±n b√∂lg…ô m√ºxbiri x…ôb…ôr verir ki, konfr...</td>\n",
       "      <td>The regional correspondent of AZERTAC reports ...</td>\n",
       "      <td>1</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208435</th>\n",
       "      <td>https://azertag.az/xeber/Tarixine_sahib_chixan...</td>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>cumhuriyyet</td>\n",
       "      <td>63610</td>\n",
       "      <td>4</td>\n",
       "      <td>Sonra Heyd…ôr ∆èliyev M…ôrk…ôzinin foyesind…ô AMEA-...</td>\n",
       "      <td>Then a book exhibition of the researches of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208436</th>\n",
       "      <td>https://azertag.az/xeber/Tarixine_sahib_chixan...</td>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>cumhuriyyet</td>\n",
       "      <td>63610</td>\n",
       "      <td>5</td>\n",
       "      <td>T…ôdbir i≈ütirak√ßƒ±larƒ± s…ôrgid…ô tariximizi …ôks et...</td>\n",
       "      <td>The participants of the event got acquainted w...</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492422</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>73</td>\n",
       "      <td>Bu is…ô √∂zl√ºy√ºnd…ô XX …ôsr tariximizd…ô yeni-yeni ...</td>\n",
       "      <td>This in itself has led to the opening of new v...</td>\n",
       "      <td>3</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492423</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>74</td>\n",
       "      <td>1998-ci ild…ôn b…ôri respublikamƒ±zda 31 mart h…ôr...</td>\n",
       "      <td>Since 1998, March 31 has been celebrated annua...</td>\n",
       "      <td>8</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492424</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>75</td>\n",
       "      <td>Bu hadis…ôl…ôri, onlarƒ±n d…ôrsl…ôrini unutmaƒüa haq...</td>\n",
       "      <td>We have no right to forget these events and th...</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492425</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>76</td>\n",
       "      <td>Tarix he√ß zaman unudulmur, h…ôm d…ô yazƒ±lƒ±r.</td>\n",
       "      <td>History is never forgotten, but also written.</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492426</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>77</td>\n",
       "      <td>Erm…ôni v…ôh≈üilikl…ôri Az…ôrbaycan tarixinin qanla...</td>\n",
       "      <td>Although the Armenian atrocities are a page wr...</td>\n",
       "      <td>2</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198758 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       url           category  \\\n",
       "1208432  https://azertag.az/xeber/Tarixine_sahib_chixan...  C√úMHURƒ∞YY∆èT - 100   \n",
       "1208433  https://azertag.az/xeber/Tarixine_sahib_chixan...  C√úMHURƒ∞YY∆èT - 100   \n",
       "1208434  https://azertag.az/xeber/Tarixine_sahib_chixan...  C√úMHURƒ∞YY∆èT - 100   \n",
       "1208435  https://azertag.az/xeber/Tarixine_sahib_chixan...  C√úMHURƒ∞YY∆èT - 100   \n",
       "1208436  https://azertag.az/xeber/Tarixine_sahib_chixan...  C√úMHURƒ∞YY∆èT - 100   \n",
       "...                                                    ...                ...   \n",
       "3492422  https://azertag.az/xeber/31_mart___azerbaycanl...        QAN YADDA≈ûI   \n",
       "3492423  https://azertag.az/xeber/31_mart___azerbaycanl...        QAN YADDA≈ûI   \n",
       "3492424  https://azertag.az/xeber/31_mart___azerbaycanl...        QAN YADDA≈ûI   \n",
       "3492425  https://azertag.az/xeber/31_mart___azerbaycanl...        QAN YADDA≈ûI   \n",
       "3492426  https://azertag.az/xeber/31_mart___azerbaycanl...        QAN YADDA≈ûI   \n",
       "\n",
       "                   sub_category  news_id  order_number  \\\n",
       "1208432             cumhuriyyet    63610             1   \n",
       "1208433             cumhuriyyet    63610             2   \n",
       "1208434             cumhuriyyet    63610             3   \n",
       "1208435             cumhuriyyet    63610             4   \n",
       "1208436             cumhuriyyet    63610             5   \n",
       "...                         ...      ...           ...   \n",
       "3492422  bloody_memory_31_march   317210            73   \n",
       "3492423  bloody_memory_31_march   317210            74   \n",
       "3492424  bloody_memory_31_march   317210            75   \n",
       "3492425  bloody_memory_31_march   317210            76   \n",
       "3492426  bloody_memory_31_march   317210            77   \n",
       "\n",
       "                                              text_content  \\\n",
       "1208432  ≈û…ômkird…ôki Heyd…ôr ∆èliyev M…ôrk…ôzind…ô Az…ôrbaycan...   \n",
       "1208433  Konfransda ≈û…ômkir Rayon ƒ∞cra Hakimiyy…ôtinin ba...   \n",
       "1208434  AZ∆èRTAC-ƒ±n b√∂lg…ô m√ºxbiri x…ôb…ôr verir ki, konfr...   \n",
       "1208435  Sonra Heyd…ôr ∆èliyev M…ôrk…ôzinin foyesind…ô AMEA-...   \n",
       "1208436  T…ôdbir i≈ütirak√ßƒ±larƒ± s…ôrgid…ô tariximizi …ôks et...   \n",
       "...                                                    ...   \n",
       "3492422  Bu is…ô √∂zl√ºy√ºnd…ô XX …ôsr tariximizd…ô yeni-yeni ...   \n",
       "3492423  1998-ci ild…ôn b…ôri respublikamƒ±zda 31 mart h…ôr...   \n",
       "3492424  Bu hadis…ôl…ôri, onlarƒ±n d…ôrsl…ôrini unutmaƒüa haq...   \n",
       "3492425         Tarix he√ß zaman unudulmur, h…ôm d…ô yazƒ±lƒ±r.   \n",
       "3492426  Erm…ôni v…ôh≈üilikl…ôri Az…ôrbaycan tarixinin qanla...   \n",
       "\n",
       "                                                   text_en  non-alpha  len  \n",
       "1208432  A scientific-practical conference dedicated to...          5  155  \n",
       "1208433  At the conference, Alimpasha Mammadov, Head of...         21  741  \n",
       "1208434  The regional correspondent of AZERTAC reports ...          1  223  \n",
       "1208435  Then a book exhibition of the researches of th...          1  129  \n",
       "1208436  The participants of the event got acquainted w...          1  108  \n",
       "...                                                    ...        ...  ...  \n",
       "3492422  This in itself has led to the opening of new v...          3   85  \n",
       "3492423  Since 1998, March 31 has been celebrated annua...          8  121  \n",
       "3492424  We have no right to forget these events and th...          1   58  \n",
       "3492425      History is never forgotten, but also written.          2   45  \n",
       "3492426  Although the Armenian atrocities are a page wr...          2  228  \n",
       "\n",
       "[198758 rows x 9 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['category','text_en_lower']].to_csv('for_eda.tsv',sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1208432</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208433</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208434</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208435</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208436</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492422</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492423</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492424</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492425</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492426</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198990 rows √ó 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [1208432, 1208433, 1208434, 1208435, 1208436, 1208437, 1208438, 1208439, 1208440, 1208441, 1208442, 1208581, 1208582, 1208583, 1208584, 1208585, 1208586, 1208587, 1208588, 1208589, 1208590, 1208591, 1208592, 1208593, 1208594, 1208595, 1208596, 1208597, 1208598, 1208599, 1208600, 1208601, 1208602, 1208603, 1208604, 1208605, 1208606, 1208607, 1208608, 1208609, 1208610, 1208611, 1208612, 1208613, 1208614, 1208615, 1208616, 1208617, 1208618, 1208619, 1208620, 1208621, 1208622, 1208623, 1208624, 1208625, 1208626, 1208627, 1208628, 1208629, 1208630, 1208631, 1208632, 1208633, 1208634, 1208635, 1208636, 1208637, 1208638, 1208639, 1208640, 1208641, 1208642, 1208643, 1208644, 1208645, 1208646, 1208647, 1208648, 1208649, 1208650, 1208651, 1208652, 1208653, 1208654, 1208655, 1208656, 1208657, 1208658, 1208659, 1208660, 1208661, 1208662, 1208663, 1208664, 1208665, 1208666, 1208667, 1208668, 1208669, ...]\n",
       "\n",
       "[198990 rows x 0 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.drop(test_df[test_df['len']==test_df['non-alpha']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>news_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>text_content</th>\n",
       "      <th>text_en</th>\n",
       "      <th>non-alpha</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3334980</th>\n",
       "      <td>https://azertag.az/xeber/Dekabr_ayi_uchun_Fran...</td>\n",
       "      <td>D√úNYA</td>\n",
       "      <td>oddly_enough</td>\n",
       "      <td>304646</td>\n",
       "      <td>49</td>\n",
       "      <td>....</td>\n",
       "      <td>....</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356560</th>\n",
       "      <td>https://azertag.az/xeber/Masallinin_Sirebil_ke...</td>\n",
       "      <td>D√úNYA</td>\n",
       "      <td>oddly_enough</td>\n",
       "      <td>306324</td>\n",
       "      <td>10</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399018</th>\n",
       "      <td>https://azertag.az/xeber/IRALI_Ictimai_Birliyi...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_20_january</td>\n",
       "      <td>309886</td>\n",
       "      <td>4</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399056</th>\n",
       "      <td>https://azertag.az/xeber/Meksikanin_iki_en_nuf...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_20_january</td>\n",
       "      <td>309889</td>\n",
       "      <td>8</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399194</th>\n",
       "      <td>https://azertag.az/xeber/20_Yanvar_xalqimizin_...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_20_january</td>\n",
       "      <td>309902</td>\n",
       "      <td>12</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490865</th>\n",
       "      <td>https://azertag.az/xeber/YASAMAL_RAYONUNDA_MAR...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317095</td>\n",
       "      <td>9</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491473</th>\n",
       "      <td>https://azertag.az/xeber/Susa_teatri_Sumqayit_...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317138</td>\n",
       "      <td>16</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491551</th>\n",
       "      <td>https://azertag.az/xeber/Zaqatalada_Azerbaycan...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317146</td>\n",
       "      <td>13</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491986</th>\n",
       "      <td>https://azertag.az/xeber/Ankara_Il_qezeti_bir_...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317184</td>\n",
       "      <td>5</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492029</th>\n",
       "      <td>https://azertag.az/xeber/Kiyevde_azerbaycanlil...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317189</td>\n",
       "      <td>7</td>\n",
       "      <td>######</td>\n",
       "      <td>######</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       url     category  \\\n",
       "3334980  https://azertag.az/xeber/Dekabr_ayi_uchun_Fran...        D√úNYA   \n",
       "3356560  https://azertag.az/xeber/Masallinin_Sirebil_ke...        D√úNYA   \n",
       "3399018  https://azertag.az/xeber/IRALI_Ictimai_Birliyi...  QAN YADDA≈ûI   \n",
       "3399056  https://azertag.az/xeber/Meksikanin_iki_en_nuf...  QAN YADDA≈ûI   \n",
       "3399194  https://azertag.az/xeber/20_Yanvar_xalqimizin_...  QAN YADDA≈ûI   \n",
       "...                                                    ...          ...   \n",
       "3490865  https://azertag.az/xeber/YASAMAL_RAYONUNDA_MAR...  QAN YADDA≈ûI   \n",
       "3491473  https://azertag.az/xeber/Susa_teatri_Sumqayit_...  QAN YADDA≈ûI   \n",
       "3491551  https://azertag.az/xeber/Zaqatalada_Azerbaycan...  QAN YADDA≈ûI   \n",
       "3491986  https://azertag.az/xeber/Ankara_Il_qezeti_bir_...  QAN YADDA≈ûI   \n",
       "3492029  https://azertag.az/xeber/Kiyevde_azerbaycanlil...  QAN YADDA≈ûI   \n",
       "\n",
       "                     sub_category  news_id  order_number text_content text_en  \\\n",
       "3334980              oddly_enough   304646            49         ....    ....   \n",
       "3356560              oddly_enough   306324            10       ######  ######   \n",
       "3399018  bloody_memory_20_january   309886             4       ######  ######   \n",
       "3399056  bloody_memory_20_january   309889             8       ######  ######   \n",
       "3399194  bloody_memory_20_january   309902            12       ######  ######   \n",
       "...                           ...      ...           ...          ...     ...   \n",
       "3490865    bloody_memory_31_march   317095             9       ######  ######   \n",
       "3491473    bloody_memory_31_march   317138            16       ######  ######   \n",
       "3491551    bloody_memory_31_march   317146            13       ######  ######   \n",
       "3491986    bloody_memory_31_march   317184             5       ######  ######   \n",
       "3492029    bloody_memory_31_march   317189             7       ######  ######   \n",
       "\n",
       "         non-alpha  len  \n",
       "3334980          4    4  \n",
       "3356560          6    6  \n",
       "3399018          6    6  \n",
       "3399056          6    6  \n",
       "3399194          6    6  \n",
       "...            ...  ...  \n",
       "3490865          6    6  \n",
       "3491473          6    6  \n",
       "3491551          6    6  \n",
       "3491986          6    6  \n",
       "3492029          6    6  \n",
       "\n",
       "[220 rows x 9 columns]"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[test_df['len']==test_df['non-alpha']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['text_en_lower'] = test_df['text_en'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1208432    a scientific-practical conference dedicated to...\n",
       "1208433    at the conference, alimpasha mammadov, head of...\n",
       "1208434    the regional correspondent of azertac reports ...\n",
       "1208435    then a book exhibition of the researches of th...\n",
       "1208436    the participants of the event got acquainted w...\n",
       "                                 ...                        \n",
       "3492422    this in itself has led to the opening of new v...\n",
       "3492423    since 1998, march 31 has been celebrated annua...\n",
       "3492424    we have no right to forget these events and th...\n",
       "3492425        history is never forgotten, but also written.\n",
       "3492426    although the armenian atrocities are a page wr...\n",
       "Name: text_en_lower, Length: 198770, dtype: object"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text_en_lower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df = pd.read_csv('eda_for_eda.tsv', sep='\\t').iloc[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-e544f6117d33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meda_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'translated_augmented_2kk.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(self, path, compression, protocol)\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpickle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2676\u001b[0;31m         \u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2678\u001b[0m     def to_clipboard(\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/pandas/io/pickle.py\u001b[0m in \u001b[0;36mto_pickle\u001b[0;34m(obj, filepath_or_buffer, compression, protocol)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_f\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0m_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eda_df.to_pickle('translated_augmented_2kk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda_df = pd.read_pickle('translated_augmented_2kk.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "practical conference dedicated to the anniversary of the azerbaijan democratic republic was held the heydar aliyev center in shamkir\n",
      "≈û…ômkird…ô Heyd…ôr ∆èliyev M…ôrk…ôzi Az…ôrbaycan Xalq C√ºmhuriyy…ôtinin ild√∂n√ºm√ºn…ô h…ôsr olunmu≈ü praktik konfrans ke√ßirildi\n",
      "a scientific practical conference dedicated to the 100th anniversary of the democratic republic was held at the heydar aliyev center in\n",
      "Heyd…ôr ∆èliyev M…ôrk…ôzind…ô Demokratik Respublikanƒ±n 100 illik yubileyin…ô h…ôsr olunmu≈ü elmi praktik konfrans ke√ßirildi\n",
      "a scientific practical conference dedicated to the 100th anniversary of the azerbaijan democratic republic azerbajdzhan republic was held at the heydar aliyev day of remembrance center in shamkir\n",
      "Az…ôrbaycan Xalq C√ºmhuriyy…ôtinin 100 illik yubileyin…ô h…ôsr olunmu≈ü elmi praktik konfrans ≈û…ômkird…ô Heyd…ôr ∆èliyevin Heyd…ôr ∆èliyev G√ºn√ºind…ô ke√ßirildi\n",
      "a scientific practical to the 100th anniversary of the azerbaijan democratic republic was held at the heydar aliyev center shamkir\n",
      "≈û…ômkir Heyd…ôr ∆èliyev M…ôrk…ôzind…ô Az…ôrbaycan Xalq C√ºmhuriyy…ôtinin 100 illik yubileyi √º√ß√ºn elmi praktikdir\n",
      "a scientific practical conference at to the 100th anniversary of the azerbaijan democratic republic was held the dedicated heydar aliyev center in shamkir\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-a8395b73610b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meda_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'az'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/googletrans/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0mtoken_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/googletrans/client.py\u001b[0m in \u001b[0;36m_translate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;34m'rt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         }\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_Exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, files, json, params, headers, cookies, auth, allow_redirects, timeout)\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, data, files, json, params, headers, cookies, auth, allow_redirects, timeout)\u001b[0m\n\u001b[1;32m    599\u001b[0m         )\n\u001b[1;32m    600\u001b[0m         return self.send(\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_redirects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m         )\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, allow_redirects, timeout)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         response = self.send_handling_redirects(\n\u001b[0;32m--> 621\u001b[0;31m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m         )\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend_handling_redirects\u001b[0;34m(self, request, auth, timeout, allow_redirects, history)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             response = self.send_handling_auth(\n\u001b[0;32m--> 648\u001b[0;31m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m             )\n\u001b[1;32m    650\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend_handling_auth\u001b[0;34m(self, request, history, auth, timeout)\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_flow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_response_body\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend_single_request\u001b[0;34m(self, request, timeout)\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             )\n\u001b[1;32m    721\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, headers, stream, timeout)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                 response = connection.request(\n\u001b[0;32m--> 153\u001b[0;31m                     \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m                 )\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mNewConnectionRequired\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, headers, stream, timeout)\u001b[0m\n\u001b[1;32m     63\u001b[0m                         \u001b[0;34m\"open_socket origin=%r timeout=%r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     )\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mConnectionState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREADY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConnectionState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIDLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36m_open_socket\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             return self.backend.open_tcp_stream(\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             )\n\u001b[1;32m     88\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mopen_tcp_stream\u001b[0;34m(self, hostname, port, ssl_context, timeout)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mssl_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 sock = ssl_context.wrap_socket(\n\u001b[0;32m--> 137\u001b[0;31m                     \u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhostname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ascii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 )\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSyncSocketStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    405\u001b[0m                          \u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                          \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                          _context=self, _session=session)\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     def wrap_bio(self, incoming, outgoing, server_side=False,\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sock, keyfile, certfile, server_side, cert_reqs, ssl_version, ca_certs, do_handshake_on_connect, family, type, proto, fileno, suppress_ragged_eofs, npn_protocols, ciphers, server_hostname, _context, _session)\u001b[0m\n\u001b[1;32m    815\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1075\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1077\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1078\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;34m\"\"\"Start the SSL/TLS handshake.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for row in eda_df['text en']:\n",
    "    print(row)\n",
    "    res = translator.translate(row, dest='az', src='en').text\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eda_df['text_az'] = eda_df['text en'].safe_map(retranslate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['C√úMHURƒ∞YY∆èT - 100',\n",
       "        'practical conference dedicated to the anniversary of the azerbaijan democratic republic was held the heydar aliyev center in shamkir'],\n",
       "       ['C√úMHURƒ∞YY∆èT - 100',\n",
       "        'a scientific practical conference dedicated to the 100th anniversary of the democratic republic was held at the heydar aliyev center in'],\n",
       "       ['C√úMHURƒ∞YY∆èT - 100',\n",
       "        'a scientific practical conference dedicated to the 100th anniversary of the azerbaijan democratic republic azerbajdzhan republic was held at the heydar aliyev day of remembrance center in shamkir'],\n",
       "       ...,\n",
       "       ['QAN YADDA≈ûI',\n",
       "        'although the armenian atrocities are a page all in written in the history of azerbaijan strong azerbaijan is always able to successfully overcome blood problems it having a voice and influence in the region where by is located'],\n",
       "       ['QAN YADDA≈ûI',\n",
       "        'although the armenian atrocities are a page written in rake in the history of azerbaijan strong azerbaijan is always capable to successfully overcome all problems by having a voice and influence in the region where it is site'],\n",
       "       ['QAN YADDA≈ûI',\n",
       "        'although the armenian atrocities are a page written in blood in the history of azerbaijan strong azerbaijan is always able to successfully overcome all problems by having a voice and influence in the region where it is located ']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>practical conference dedicated to the annivers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>a scientific practical conference dedicated to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>a scientific practical conference dedicated to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>a scientific practical to the 100th anniversar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>a scientific practical conference at to the 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987579</th>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>although the armenian a page written in blood ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987580</th>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>although the armenian atrocities are a page in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987581</th>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>although the armenian atrocities are a page al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987582</th>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>although the armenian atrocities are a page wr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987583</th>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>although the armenian atrocities are a page wr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1987575 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  category                                            text en\n",
       "9        C√úMHURƒ∞YY∆èT - 100  practical conference dedicated to the annivers...\n",
       "10       C√úMHURƒ∞YY∆èT - 100  a scientific practical conference dedicated to...\n",
       "11       C√úMHURƒ∞YY∆èT - 100  a scientific practical conference dedicated to...\n",
       "12       C√úMHURƒ∞YY∆èT - 100  a scientific practical to the 100th anniversar...\n",
       "13       C√úMHURƒ∞YY∆èT - 100  a scientific practical conference at to the 10...\n",
       "...                    ...                                                ...\n",
       "1987579        QAN YADDA≈ûI  although the armenian a page written in blood ...\n",
       "1987580        QAN YADDA≈ûI  although the armenian atrocities are a page in...\n",
       "1987581        QAN YADDA≈ûI  although the armenian atrocities are a page al...\n",
       "1987582        QAN YADDA≈ûI  although the armenian atrocities are a page wr...\n",
       "1987583        QAN YADDA≈ûI  although the armenian atrocities are a page wr...\n",
       "\n",
       "[1987575 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eda_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/checkpoints/checkpoints.py:126: UserWarning: Failure on index 60\n",
      "  warnings.warn(\"Failure on index {0}\".format(len(self._results)), UserWarning)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-be3ad659b3b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meda_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_az'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meda_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text en'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretranslate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/checkpoints/checkpoints.py\u001b[0m in \u001b[0;36msafe_map\u001b[0;34m(srs, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Populate `self.results`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrs_remaining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                 \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# If we got here, then we didn't exit out due to an exception, and we can finish the method successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/checkpoints/checkpoints.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-604f29ec3d02>\u001b[0m in \u001b[0;36mretranslate\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mretranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'az'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# print(batch['text'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# print(batch['text_en'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/ml/lib/python3.6/site-packages/googletrans/client.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(self, text, dest, src)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m         \u001b[0mparsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;31m# not sure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mshould_spacing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             raise TypeError('the JSON object must be str, bytes or bytearray, '\n\u001b[0;32m--> 348\u001b[0;31m                             'not {!r}'.format(s.__class__.__name__))\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetect_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogatepass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "eda_df['text_az'] = eda_df['text en'].safe_map(retranslate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for i in range(8):\n",
    "    path = \"/home/greamdesu/GF/azer_translated_pkl/df_neaural_{}_final.pkl\".format(i)\n",
    "    dfs.append(pd.read_pickle(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a56a62247f8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_az'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['text_az'] = df['text_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>practical conference dedicated to the annivers...</td>\n",
       "      <td>Azerbaycan Demokrat Cumhuriyetinin kurulu≈ü yƒ±l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>a scientific practical conference dedicated to...</td>\n",
       "      <td>Demokrat republicin 100. yƒ±ld√∂n√ºm√º m√ºnasebetiy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>a scientific practical conference dedicated to...</td>\n",
       "      <td>Azerbaycan Demokrat Cumhuriyetinin 100-ci il…ô ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>a scientific practical to the 100th anniversar...</td>\n",
       "      <td>Azerbaijan Demokrat Cumhuriyetinin 100-ci il…ô ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C√úMHURƒ∞YY∆èT - 100</td>\n",
       "      <td>a scientific practical conference at to the 10...</td>\n",
       "      <td>Azerbaijan Demokrat Cumhuriyetinin 100-ci il…ô ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248441</th>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>although the armenian a page written in blood ...</td>\n",
       "      <td>…ôg…ôr armeniyalƒ±lar azerbaycanlƒ±q tarixinin i√ßi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248442</th>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>although the armenian atrocities are a page in...</td>\n",
       "      <td>…ôg…ôr Ermenil…ôrin i≈ülediƒüi zul√ºm…ôl…ôr …ôs…ôbd…ô bir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248443</th>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>although the armenian atrocities are a page al...</td>\n",
       "      <td>…ôg…ôr armen okrutlarƒ± b√ºt√ºn Azerbaijan tarixini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248444</th>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>although the armenian atrocities are a page wr...</td>\n",
       "      <td>…ôg…ôr Ermeni okrutlar azerbaycanlƒ±q tarixinin b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248445</th>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>although the armenian atrocities are a page wr...</td>\n",
       "      <td>…ôg…ôr Ermeni okrutlar azerbaycanlƒ±q tarixinin i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1987575 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 category                                            text_en  \\\n",
       "0       C√úMHURƒ∞YY∆èT - 100  practical conference dedicated to the annivers...   \n",
       "1       C√úMHURƒ∞YY∆èT - 100  a scientific practical conference dedicated to...   \n",
       "2       C√úMHURƒ∞YY∆èT - 100  a scientific practical conference dedicated to...   \n",
       "3       C√úMHURƒ∞YY∆èT - 100  a scientific practical to the 100th anniversar...   \n",
       "4       C√úMHURƒ∞YY∆èT - 100  a scientific practical conference at to the 10...   \n",
       "...                   ...                                                ...   \n",
       "248441        QAN YADDA≈ûI  although the armenian a page written in blood ...   \n",
       "248442        QAN YADDA≈ûI  although the armenian atrocities are a page in...   \n",
       "248443        QAN YADDA≈ûI  although the armenian atrocities are a page al...   \n",
       "248444        QAN YADDA≈ûI  although the armenian atrocities are a page wr...   \n",
       "248445        QAN YADDA≈ûI  although the armenian atrocities are a page wr...   \n",
       "\n",
       "                                                  text_az  \n",
       "0       Azerbaycan Demokrat Cumhuriyetinin kurulu≈ü yƒ±l...  \n",
       "1       Demokrat republicin 100. yƒ±ld√∂n√ºm√º m√ºnasebetiy...  \n",
       "2       Azerbaycan Demokrat Cumhuriyetinin 100-ci il…ô ...  \n",
       "3       Azerbaijan Demokrat Cumhuriyetinin 100-ci il…ô ...  \n",
       "4       Azerbaijan Demokrat Cumhuriyetinin 100-ci il…ô ...  \n",
       "...                                                   ...  \n",
       "248441  …ôg…ôr armeniyalƒ±lar azerbaycanlƒ±q tarixinin i√ßi...  \n",
       "248442  …ôg…ôr Ermenil…ôrin i≈ülediƒüi zul√ºm…ôl…ôr …ôs…ôbd…ô bir...  \n",
       "248443  …ôg…ôr armen okrutlarƒ± b√ºt√ºn Azerbaijan tarixini...  \n",
       "248444  …ôg…ôr Ermeni okrutlar azerbaycanlƒ±q tarixinin b...  \n",
       "248445  …ôg…ôr Ermeni okrutlar azerbaycanlƒ±q tarixinin i...  \n",
       "\n",
       "[1987575 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.concat([df, df_aug])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df['text_az_lower'] = big_df['text_az'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_pickle('merged_neural.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('azertag_sentences_with_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.read_pickle('merged_neural.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>news_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>text_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ƒ∞yunun 22-d…ô Az…ôrbaycan Respublikasƒ±nƒ±n Prezid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>AZ∆èRTAC x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Bildirilib ki, …ôz…ôm…ôti v…ô g√∂z…ôlliyi il…ô m…ô≈ühur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>D√∂rd hiss…ôd…ôn ibar…ôt saray kompleksin…ô √ºmumili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492448</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>3</td>\n",
       "      <td>K√ºrd√º (sƒ±rƒ±nmƒ±≈ü qolsuz k√∂yn…ôk) ‚Äì qadƒ±n √ºst gey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492449</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>4</td>\n",
       "      <td>Bu geyim tirm…ôd…ôn v…ô m…ôxm…ôrd…ôn tikilirdi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492450</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>5</td>\n",
       "      <td>X…ôzl…ô b…ôz…ôk, sƒ±x naxƒ±≈ü vurulurdu.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492451</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>6</td>\n",
       "      <td>K√ºrd√ºn√º ≈ûu≈üada, h…ôm√ßinin Az…ôrbaycanƒ±n h…ôr yeri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492452</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>7</td>\n",
       "      <td>K√ºrd√º indi d…ô d…ôbd…ôdir.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3492453 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       url       category  \\\n",
       "0        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "1        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "2        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "3        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "4        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "...                                                    ...            ...   \n",
       "3492448  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "3492449  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "3492450  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "3492451  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "3492452  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "\n",
       "          sub_category  news_id  order_number  \\\n",
       "0        R∆èSMƒ∞ XRONƒ∞KA        1             1   \n",
       "1        R∆èSMƒ∞ XRONƒ∞KA        1             2   \n",
       "2        R∆èSMƒ∞ XRONƒ∞KA        1             3   \n",
       "3        R∆èSMƒ∞ XRONƒ∞KA        1             4   \n",
       "4        R∆èSMƒ∞ XRONƒ∞KA        1             5   \n",
       "...                ...      ...           ...   \n",
       "3492448    shusha_year   317214             3   \n",
       "3492449    shusha_year   317214             4   \n",
       "3492450    shusha_year   317214             5   \n",
       "3492451    shusha_year   317214             6   \n",
       "3492452    shusha_year   317214             7   \n",
       "\n",
       "                                              text_content  \n",
       "0        ƒ∞yunun 22-d…ô Az…ôrbaycan Respublikasƒ±nƒ±n Prezid...  \n",
       "1        AZ∆èRTAC x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...  \n",
       "2        Bildirilib ki, …ôz…ôm…ôti v…ô g√∂z…ôlliyi il…ô m…ô≈ühur...  \n",
       "3        D√∂rd hiss…ôd…ôn ibar…ôt saray kompleksin…ô √ºmumili...  \n",
       "4        Saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...  \n",
       "...                                                    ...  \n",
       "3492448  K√ºrd√º (sƒ±rƒ±nmƒ±≈ü qolsuz k√∂yn…ôk) ‚Äì qadƒ±n √ºst gey...  \n",
       "3492449          Bu geyim tirm…ôd…ôn v…ô m…ôxm…ôrd…ôn tikilirdi.  \n",
       "3492450                  X…ôzl…ô b…ôz…ôk, sƒ±x naxƒ±≈ü vurulurdu.  \n",
       "3492451  K√ºrd√ºn√º ≈ûu≈üada, h…ôm√ßinin Az…ôrbaycanƒ±n h…ôr yeri...  \n",
       "3492452                            K√ºrd√º indi d…ô d…ôbd…ôdir.  \n",
       "\n",
       "[3492453 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>news_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>text_content</th>\n",
       "      <th>text_az</th>\n",
       "      <th>text_en</th>\n",
       "      <th>text_az_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ƒ∞yunun 22-d…ô Az…ôrbaycan Respublikasƒ±nƒ±n Prezid...</td>\n",
       "      <td>ƒ∞yunun 22-d…ô Az…ôrbaycan Respublikasƒ±nƒ±n Prezid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iÃáyunun 22-d…ô az…ôrbaycan respublikasƒ±nƒ±n prezi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>AZ∆èRTAC x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...</td>\n",
       "      <td>AZ∆èRTAC x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>az…ôrtac x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Bildirilib ki, …ôz…ôm…ôti v…ô g√∂z…ôlliyi il…ô m…ô≈ühur...</td>\n",
       "      <td>Bildirilib ki, …ôz…ôm…ôti v…ô g√∂z…ôlliyi il…ô m…ô≈ühur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bildirilib ki, …ôz…ôm…ôti v…ô g√∂z…ôlliyi il…ô m…ô≈ühur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D√∂rd hiss…ôd…ôn ibar…ôt saray kompleksin…ô √ºmumili...</td>\n",
       "      <td>D√∂rd hiss…ôd…ôn ibar…ôt saray kompleksin…ô √ºmumili...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d√∂rd hiss…ôd…ôn ibar…ôt saray kompleksin…ô √ºmumili...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...</td>\n",
       "      <td>Saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248441</th>\n",
       "      <td>NaN</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>…ôg…ôr armeniyalƒ±lar azerbaycanlƒ±q tarixinin i√ßi...</td>\n",
       "      <td>although the armenian a page written in blood ...</td>\n",
       "      <td>…ôg…ôr armeniyalƒ±lar azerbaycanlƒ±q tarixinin i√ßi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248442</th>\n",
       "      <td>NaN</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>…ôg…ôr Ermenil…ôrin i≈ülediƒüi zul√ºm…ôl…ôr …ôs…ôbd…ô bir...</td>\n",
       "      <td>although the armenian atrocities are a page in...</td>\n",
       "      <td>…ôg…ôr ermenil…ôrin i≈ülediƒüi zul√ºm…ôl…ôr …ôs…ôbd…ô bir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248443</th>\n",
       "      <td>NaN</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>…ôg…ôr armen okrutlarƒ± b√ºt√ºn Azerbaijan tarixini...</td>\n",
       "      <td>although the armenian atrocities are a page al...</td>\n",
       "      <td>…ôg…ôr armen okrutlarƒ± b√ºt√ºn azerbaijan tarixini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248444</th>\n",
       "      <td>NaN</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>…ôg…ôr Ermeni okrutlar azerbaycanlƒ±q tarixinin b...</td>\n",
       "      <td>although the armenian atrocities are a page wr...</td>\n",
       "      <td>…ôg…ôr ermeni okrutlar azerbaycanlƒ±q tarixinin b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248445</th>\n",
       "      <td>NaN</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>…ôg…ôr Ermeni okrutlar azerbaycanlƒ±q tarixinin i...</td>\n",
       "      <td>although the armenian atrocities are a page wr...</td>\n",
       "      <td>…ôg…ôr ermeni okrutlar azerbaycanlƒ±q tarixinin i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5480028 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url       category  \\\n",
       "0       https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "1       https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "2       https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "3       https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "4       https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "...                                                   ...            ...   \n",
       "248441                                                NaN    QAN YADDA≈ûI   \n",
       "248442                                                NaN    QAN YADDA≈ûI   \n",
       "248443                                                NaN    QAN YADDA≈ûI   \n",
       "248444                                                NaN    QAN YADDA≈ûI   \n",
       "248445                                                NaN    QAN YADDA≈ûI   \n",
       "\n",
       "         sub_category  news_id  order_number  \\\n",
       "0       R∆èSMƒ∞ XRONƒ∞KA      1.0           1.0   \n",
       "1       R∆èSMƒ∞ XRONƒ∞KA      1.0           2.0   \n",
       "2       R∆èSMƒ∞ XRONƒ∞KA      1.0           3.0   \n",
       "3       R∆èSMƒ∞ XRONƒ∞KA      1.0           4.0   \n",
       "4       R∆èSMƒ∞ XRONƒ∞KA      1.0           5.0   \n",
       "...               ...      ...           ...   \n",
       "248441            NaN      NaN           NaN   \n",
       "248442            NaN      NaN           NaN   \n",
       "248443            NaN      NaN           NaN   \n",
       "248444            NaN      NaN           NaN   \n",
       "248445            NaN      NaN           NaN   \n",
       "\n",
       "                                             text_content  \\\n",
       "0       ƒ∞yunun 22-d…ô Az…ôrbaycan Respublikasƒ±nƒ±n Prezid...   \n",
       "1       AZ∆èRTAC x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...   \n",
       "2       Bildirilib ki, …ôz…ôm…ôti v…ô g√∂z…ôlliyi il…ô m…ô≈ühur...   \n",
       "3       D√∂rd hiss…ôd…ôn ibar…ôt saray kompleksin…ô √ºmumili...   \n",
       "4       Saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...   \n",
       "...                                                   ...   \n",
       "248441                                                NaN   \n",
       "248442                                                NaN   \n",
       "248443                                                NaN   \n",
       "248444                                                NaN   \n",
       "248445                                                NaN   \n",
       "\n",
       "                                                  text_az  \\\n",
       "0       ƒ∞yunun 22-d…ô Az…ôrbaycan Respublikasƒ±nƒ±n Prezid...   \n",
       "1       AZ∆èRTAC x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...   \n",
       "2       Bildirilib ki, …ôz…ôm…ôti v…ô g√∂z…ôlliyi il…ô m…ô≈ühur...   \n",
       "3       D√∂rd hiss…ôd…ôn ibar…ôt saray kompleksin…ô √ºmumili...   \n",
       "4       Saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...   \n",
       "...                                                   ...   \n",
       "248441  …ôg…ôr armeniyalƒ±lar azerbaycanlƒ±q tarixinin i√ßi...   \n",
       "248442  …ôg…ôr Ermenil…ôrin i≈ülediƒüi zul√ºm…ôl…ôr …ôs…ôbd…ô bir...   \n",
       "248443  …ôg…ôr armen okrutlarƒ± b√ºt√ºn Azerbaijan tarixini...   \n",
       "248444  …ôg…ôr Ermeni okrutlar azerbaycanlƒ±q tarixinin b...   \n",
       "248445  …ôg…ôr Ermeni okrutlar azerbaycanlƒ±q tarixinin i...   \n",
       "\n",
       "                                                  text_en  \\\n",
       "0                                                     NaN   \n",
       "1                                                     NaN   \n",
       "2                                                     NaN   \n",
       "3                                                     NaN   \n",
       "4                                                     NaN   \n",
       "...                                                   ...   \n",
       "248441  although the armenian a page written in blood ...   \n",
       "248442  although the armenian atrocities are a page in...   \n",
       "248443  although the armenian atrocities are a page al...   \n",
       "248444  although the armenian atrocities are a page wr...   \n",
       "248445  although the armenian atrocities are a page wr...   \n",
       "\n",
       "                                            text_az_lower  \n",
       "0       iÃáyunun 22-d…ô az…ôrbaycan respublikasƒ±nƒ±n prezi...  \n",
       "1       az…ôrtac x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...  \n",
       "2       bildirilib ki, …ôz…ôm…ôti v…ô g√∂z…ôlliyi il…ô m…ô≈ühur...  \n",
       "3       d√∂rd hiss…ôd…ôn ibar…ôt saray kompleksin…ô √ºmumili...  \n",
       "4       saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...  \n",
       "...                                                   ...  \n",
       "248441  …ôg…ôr armeniyalƒ±lar azerbaycanlƒ±q tarixinin i√ßi...  \n",
       "248442  …ôg…ôr ermenil…ôrin i≈ülediƒüi zul√ºm…ôl…ôr …ôs…ôbd…ô bir...  \n",
       "248443  …ôg…ôr armen okrutlarƒ± b√ºt√ºn azerbaijan tarixini...  \n",
       "248444  …ôg…ôr ermeni okrutlar azerbaycanlƒ±q tarixinin b...  \n",
       "248445  …ôg…ôr ermeni okrutlar azerbaycanlƒ±q tarixinin i...  \n",
       "\n",
       "[5480028 rows x 9 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_df['text_az_lower'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C∆èMƒ∞YY∆èT             1074514\n",
       "R∆èSMƒ∞ XRONƒ∞KA         719341\n",
       "ƒ∞QTƒ∞SADƒ∞YYAT          434084\n",
       "R∆èSMƒ∞ S∆èN∆èDL∆èR        338191\n",
       "ELM V∆è T∆èHSƒ∞L         270760\n",
       "REGƒ∞ONLAR             160572\n",
       "Sƒ∞YAS∆èT               159996\n",
       "M∆èD∆èNƒ∞YY∆èT            136005\n",
       "QAN YADDA≈ûI           119544\n",
       "D√úNYA                  46127\n",
       "ƒ∞DMAN                  27721\n",
       "C√úMHURƒ∞YY∆èT - 100       5220\n",
       "M√úSAHƒ∞B∆è                 233\n",
       "BA≈û X∆èB∆èRL∆èR             105\n",
       "≈ûU≈ûA ƒ∞Lƒ∞                  40\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QAN YADDA≈ûI          1312690\n",
       "C∆èMƒ∞YY∆èT             1074514\n",
       "R∆èSMƒ∞ XRONƒ∞KA         719341\n",
       "D√úNYA                 507366\n",
       "ƒ∞QTƒ∞SADƒ∞YYAT          434084\n",
       "R∆èSMƒ∞ S∆èN∆èDL∆èR        338191\n",
       "ƒ∞DMAN                 304931\n",
       "ELM V∆è T∆èHSƒ∞L         270760\n",
       "REGƒ∞ONLAR             160572\n",
       "Sƒ∞YAS∆èT               159996\n",
       "M∆èD∆èNƒ∞YY∆èT            136005\n",
       "C√úMHURƒ∞YY∆èT - 100      57420\n",
       "M√úSAHƒ∞B∆è                2563\n",
       "BA≈û X∆èB∆èRL∆èR            1155\n",
       "≈ûU≈ûA ƒ∞Lƒ∞                 440\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(big_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/home/denay/azer-bert/azertag_sentences_with_categories.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>news_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>text_content</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ƒ∞yunun 22-d…ô Az…ôrbaycan Respublikasƒ±nƒ±n Prezid...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>AZ∆èRTAC x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Bildirilib ki, …ôz…ôm…ôti v…ô g√∂z…ôlliyi il…ô m…ô≈ühur...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>D√∂rd hiss…ôd…ôn ibar…ôt saray kompleksin…ô √ºmumili...</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492448</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>3</td>\n",
       "      <td>K√ºrd√º (sƒ±rƒ±nmƒ±≈ü qolsuz k√∂yn…ôk) ‚Äì qadƒ±n √ºst gey...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492449</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>4</td>\n",
       "      <td>Bu geyim tirm…ôd…ôn v…ô m…ôxm…ôrd…ôn tikilirdi.</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492450</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>5</td>\n",
       "      <td>X…ôzl…ô b…ôz…ôk, sƒ±x naxƒ±≈ü vurulurdu.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492451</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>6</td>\n",
       "      <td>K√ºrd√ºn√º ≈ûu≈üada, h…ôm√ßinin Az…ôrbaycanƒ±n h…ôr yeri...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492452</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>7</td>\n",
       "      <td>K√ºrd√º indi d…ô d…ôbd…ôdir.</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3492453 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       url       category  \\\n",
       "0        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "1        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "2        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "3        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "4        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "...                                                    ...            ...   \n",
       "3492448  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "3492449  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "3492450  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "3492451  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "3492452  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "\n",
       "          sub_category  news_id  order_number  \\\n",
       "0        R∆èSMƒ∞ XRONƒ∞KA        1             1   \n",
       "1        R∆èSMƒ∞ XRONƒ∞KA        1             2   \n",
       "2        R∆èSMƒ∞ XRONƒ∞KA        1             3   \n",
       "3        R∆èSMƒ∞ XRONƒ∞KA        1             4   \n",
       "4        R∆èSMƒ∞ XRONƒ∞KA        1             5   \n",
       "...                ...      ...           ...   \n",
       "3492448    shusha_year   317214             3   \n",
       "3492449    shusha_year   317214             4   \n",
       "3492450    shusha_year   317214             5   \n",
       "3492451    shusha_year   317214             6   \n",
       "3492452    shusha_year   317214             7   \n",
       "\n",
       "                                              text_content  count  \n",
       "0        ƒ∞yunun 22-d…ô Az…ôrbaycan Respublikasƒ±nƒ±n Prezid...     21  \n",
       "1        AZ∆èRTAC x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...     11  \n",
       "2        Bildirilib ki, …ôz…ôm…ôti v…ô g√∂z…ôlliyi il…ô m…ô≈ühur...     20  \n",
       "3        D√∂rd hiss…ôd…ôn ibar…ôt saray kompleksin…ô √ºmumili...     22  \n",
       "4        Saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...     13  \n",
       "...                                                    ...    ...  \n",
       "3492448  K√ºrd√º (sƒ±rƒ±nmƒ±≈ü qolsuz k√∂yn…ôk) ‚Äì qadƒ±n √ºst gey...      8  \n",
       "3492449          Bu geyim tirm…ôd…ôn v…ô m…ôxm…ôrd…ôn tikilirdi.      6  \n",
       "3492450                  X…ôzl…ô b…ôz…ôk, sƒ±x naxƒ±≈ü vurulurdu.      5  \n",
       "3492451  K√ºrd√ºn√º ≈ûu≈üada, h…ôm√ßinin Az…ôrbaycanƒ±n h…ôr yeri...      7  \n",
       "3492452                            K√ºrd√º indi d…ô d…ôbd…ôdir.      4  \n",
       "\n",
       "[3492453 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count'] = df['text_content'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted = df[(df['count']<15) & (df['count']>10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted = counted[~counted['category'].isin(['≈ûU≈ûA ƒ∞Lƒ∞', 'BA≈û X∆èB∆èRL∆èR'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>sub_category</th>\n",
       "      <th>news_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>text_content</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>AZ∆èRTAC x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>‚ÄúNurullaboy‚Äù sarayƒ± milli v…ô Avropa memarlƒ±q √º...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>Bu da h…ômin d√∂vrd…ô ≈ü…ôh…ôrsalma sah…ôsind…ô √ºst√ºnl...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://azertag.az/xeber/Dovlet_baschilari_Xiv...</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>R∆èSMƒ∞ XRONƒ∞KA</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Qƒ±zƒ±lƒ± v…ô r…ôngli r…ôsml…ôrl…ô √∂rt√ºlm√º≈ü m…ô≈ühur Xiv...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492421</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>72</td>\n",
       "      <td>Mart hadis…ôl…ôrinin saxtala≈üdƒ±rƒ±lmasƒ± xalqƒ±mƒ±za...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492422</th>\n",
       "      <td>https://azertag.az/xeber/31_mart___azerbaycanl...</td>\n",
       "      <td>QAN YADDA≈ûI</td>\n",
       "      <td>bloody_memory_31_march</td>\n",
       "      <td>317210</td>\n",
       "      <td>73</td>\n",
       "      <td>Bu is…ô √∂zl√ºy√ºnd…ô XX …ôsr tariximizd…ô yeni-yeni ...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492431</th>\n",
       "      <td>https://azertag.az/xeber/Diaspor_Genclerinin_I...</td>\n",
       "      <td>REGƒ∞ONLAR</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317212</td>\n",
       "      <td>1</td>\n",
       "      <td>Diaspor G…ôncl…ôrinin III Yay D√º≈ü…ôrg…ôsinin i≈ütir...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492438</th>\n",
       "      <td>https://azertag.az/xeber/Diaspor_Genclerinin_I...</td>\n",
       "      <td>REGƒ∞ONLAR</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317212</td>\n",
       "      <td>8</td>\n",
       "      <td>Bundan ba≈üqa, …ôyl…ônc…ôli proqramlarƒ±n v…ô intell...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492446</th>\n",
       "      <td>https://azertag.az/xeber/Susa_medeniyyetinin_i...</td>\n",
       "      <td>M∆èD∆èNƒ∞YY∆èT</td>\n",
       "      <td>shusha_year</td>\n",
       "      <td>317214</td>\n",
       "      <td>1</td>\n",
       "      <td>M…ôd…ôniyy…ôt Nazirliyinin ‚Äú≈ûu≈üa m…ôd…ôniyy…ôtinin i...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>623658 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       url       category  \\\n",
       "1        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "4        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "7        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "8        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "9        https://azertag.az/xeber/Dovlet_baschilari_Xiv...  R∆èSMƒ∞ XRONƒ∞KA   \n",
       "...                                                    ...            ...   \n",
       "3492421  https://azertag.az/xeber/31_mart___azerbaycanl...    QAN YADDA≈ûI   \n",
       "3492422  https://azertag.az/xeber/31_mart___azerbaycanl...    QAN YADDA≈ûI   \n",
       "3492431  https://azertag.az/xeber/Diaspor_Genclerinin_I...      REGƒ∞ONLAR   \n",
       "3492438  https://azertag.az/xeber/Diaspor_Genclerinin_I...      REGƒ∞ONLAR   \n",
       "3492446  https://azertag.az/xeber/Susa_medeniyyetinin_i...     M∆èD∆èNƒ∞YY∆èT   \n",
       "\n",
       "                   sub_category  news_id  order_number  \\\n",
       "1                 R∆èSMƒ∞ XRONƒ∞KA        1             2   \n",
       "4                 R∆èSMƒ∞ XRONƒ∞KA        1             5   \n",
       "7                 R∆èSMƒ∞ XRONƒ∞KA        1             8   \n",
       "8                 R∆èSMƒ∞ XRONƒ∞KA        1             9   \n",
       "9                 R∆èSMƒ∞ XRONƒ∞KA        1            10   \n",
       "...                         ...      ...           ...   \n",
       "3492421  bloody_memory_31_march   317210            72   \n",
       "3492422  bloody_memory_31_march   317210            73   \n",
       "3492431             shusha_year   317212             1   \n",
       "3492438             shusha_year   317212             8   \n",
       "3492446             shusha_year   317214             1   \n",
       "\n",
       "                                              text_content  count  \n",
       "1        AZ∆èRTAC x…ôb…ôr verir ki, saray kompleksi bar…ôd…ô...     11  \n",
       "4        Saray kompleksind…ôki b√ºt√ºn tikilil…ôr uzunluƒüu ...     13  \n",
       "7        ‚ÄúNurullaboy‚Äù sarayƒ± milli v…ô Avropa memarlƒ±q √º...     11  \n",
       "8        Bu da h…ômin d√∂vrd…ô ≈ü…ôh…ôrsalma sah…ôsind…ô √ºst√ºnl...     11  \n",
       "9        Qƒ±zƒ±lƒ± v…ô r…ôngli r…ôsml…ôrl…ô √∂rt√ºlm√º≈ü m…ô≈ühur Xiv...     13  \n",
       "...                                                    ...    ...  \n",
       "3492421  Mart hadis…ôl…ôrinin saxtala≈üdƒ±rƒ±lmasƒ± xalqƒ±mƒ±za...     13  \n",
       "3492422  Bu is…ô √∂zl√ºy√ºnd…ô XX …ôsr tariximizd…ô yeni-yeni ...     12  \n",
       "3492431  Diaspor G…ôncl…ôrinin III Yay D√º≈ü…ôrg…ôsinin i≈ütir...     11  \n",
       "3492438  Bundan ba≈üqa, …ôyl…ônc…ôli proqramlarƒ±n v…ô intell...     11  \n",
       "3492446  M…ôd…ôniyy…ôt Nazirliyinin ‚Äú≈ûu≈üa m…ôd…ôniyy…ôtinin i...     12  \n",
       "\n",
       "[623658 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "C∆èMƒ∞YY∆èT             174775\n",
       "R∆èSMƒ∞ XRONƒ∞KA        148667\n",
       "ƒ∞QTƒ∞SADƒ∞YYAT          79927\n",
       "R∆èSMƒ∞ S∆èN∆èDL∆èR        54040\n",
       "ELM V∆è T∆èHSƒ∞L         43483\n",
       "REGƒ∞ONLAR             32050\n",
       "M∆èD∆èNƒ∞YY∆èT            28304\n",
       "Sƒ∞YAS∆èT               25020\n",
       "QAN YADDA≈ûI           18624\n",
       "D√úNYA                 11078\n",
       "ƒ∞DMAN                  6834\n",
       "C√úMHURƒ∞YY∆èT - 100       804\n",
       "M√úSAHƒ∞B∆è                 52\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counted.value_counts('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = counted.groupby(['category']).apply(lambda grp: grp.sample(n=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss.to_excel('for_survey.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = xxx.drop(columns=['url', 'sub_category', 'news_id', 'order_number', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "01_how-to-train.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "ML (main)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016d7c8318f742c1943464b08232a510": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "04e7e6d291da49d5816dc98a2904e95c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39c23c6a972b419eb2eeeebafeaedc22",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_8388e9da9da4492c98c19235ca5fc1b5",
      "value": " 15228/15228 [2:46:46&lt;00:00,  1.52it/s]"
     }
    },
    "0989d41a4da24e9ebff377e02127642c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d295dd80550447d88da0f04ce36a22ff",
       "IPY_MODEL_04e7e6d291da49d5816dc98a2904e95c"
      ],
      "layout": "IPY_MODEL_42c6061ef7e44f179db5a6e3551c0f17"
     }
    },
    "39c23c6a972b419eb2eeeebafeaedc22": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "40bf955ba0284e84b198da6be8654219": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "42c6061ef7e44f179db5a6e3551c0f17": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6feb10aeb43147e6aba028d065947ae8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "837c9ddc3d594e088891874560c646b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Epoch: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe20a8dae6e84628b5076d02183090f5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_40bf955ba0284e84b198da6be8654219",
      "value": 1
     }
    },
    "8388e9da9da4492c98c19235ca5fc1b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93b3f9eae3cb4e3e859cf456e3547c6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a491e8caa0a048beb3b5259f14eb233f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a58a66392b644b1384661e850c077a6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_837c9ddc3d594e088891874560c646b8",
       "IPY_MODEL_dbf50873d62c4ba39321faefbed0cca5"
      ],
      "layout": "IPY_MODEL_a491e8caa0a048beb3b5259f14eb233f"
     }
    },
    "d295dd80550447d88da0f04ce36a22ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Iteration: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_016d7c8318f742c1943464b08232a510",
      "max": 15228,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7d8c3a4fecd40778e32966b29ea65a1",
      "value": 15228
     }
    },
    "dbf50873d62c4ba39321faefbed0cca5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6feb10aeb43147e6aba028d065947ae8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_93b3f9eae3cb4e3e859cf456e3547c6d",
      "value": " 1/1 [2:46:46&lt;00:00, 10006.17s/it]"
     }
    },
    "e7d8c3a4fecd40778e32966b29ea65a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fe20a8dae6e84628b5076d02183090f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
